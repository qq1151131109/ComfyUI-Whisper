#!/usr/bin/env python3
"""
WhisperXè°ƒè¯•è„šæœ¬
ç³»ç»Ÿæ€§æµ‹è¯•æ¯ä¸ªç¯èŠ‚ï¼Œæ‰¾å‡ºé—®é¢˜æ‰€åœ¨
"""

import os
import sys
import json
import logging
import traceback

# æ·»åŠ ComfyUIè·¯å¾„
sys.path.append('/shenglin/ComfyUI')

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def test_imports():
    """æµ‹è¯•ä¾èµ–å¯¼å…¥"""
    print("=" * 50)
    print("ğŸ” æµ‹è¯•1: ä¾èµ–å¯¼å…¥æ£€æŸ¥")
    print("=" * 50)
    
    try:
        import whisperx
        print(f"âœ… WhisperXç‰ˆæœ¬: {getattr(whisperx, '__version__', 'Unknown')}")
    except ImportError as e:
        print(f"âŒ WhisperXå¯¼å…¥å¤±è´¥: {e}")
        return False
    
    try:
        import pyannote.audio
        print(f"âœ… Pyannoteç‰ˆæœ¬: {getattr(pyannote.audio, '__version__', 'Unknown')}")
    except ImportError as e:
        print(f"âŒ Pyannoteå¯¼å…¥å¤±è´¥: {e}")
    
    try:
        import torch
        print(f"âœ… PyTorchç‰ˆæœ¬: {torch.__version__}")
        print(f"âœ… CUDAå¯ç”¨: {torch.cuda.is_available()}")
        if torch.cuda.is_available():
            print(f"âœ… CUDAç‰ˆæœ¬: {torch.version.cuda}")
    except ImportError as e:
        print(f"âŒ PyTorchå¯¼å…¥å¤±è´¥: {e}")
    
    return True

def test_whisperx_basic():
    """æµ‹è¯•WhisperXåŸºç¡€åŠŸèƒ½"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯•2: WhisperXåŸºç¡€åŠŸèƒ½")
    print("=" * 50)
    
    try:
        import whisperx
        import torch
        
        # æµ‹è¯•æ¨¡å‹åŠ è½½
        print("ğŸ“¥ åŠ è½½WhisperXæ¨¡å‹...")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ä½¿ç”¨è®¾å¤‡: {device}")
        
        model = whisperx.load_model("base", device=device)
        print("âœ… WhisperXæ¨¡å‹åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•å¯¹é½æ¨¡å‹åŠ è½½
        print("ğŸ“¥ åŠ è½½å¯¹é½æ¨¡å‹...")
        try:
            align_model, metadata = whisperx.load_align_model(language_code="en", device=device)
            print("âœ… å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“‹ å¯¹é½æ¨¡å‹metadata keys: {list(metadata.keys()) if metadata else 'None'}")
            return model, align_model, metadata
        except Exception as e:
            print(f"âŒ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            return model, None, None
            
    except Exception as e:
        print(f"âŒ WhisperXåŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        print(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None, None, None

def create_test_audio():
    """åˆ›å»ºæµ‹è¯•éŸ³é¢‘æ–‡ä»¶"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯•3: åˆ›å»ºæµ‹è¯•éŸ³é¢‘")
    print("=" * 50)
    
    # æŸ¥æ‰¾ç°æœ‰çš„éŸ³é¢‘æ–‡ä»¶
    test_paths = [
        "/shenglin/ComfyUI/input/H_V2VinfiniteTalk_00004-audio.mp4",
        "/shenglin/ComfyUI/temp/whisperx_*.wav"
    ]
    
    for path_pattern in test_paths:
        if '*' in path_pattern:
            import glob
            files = glob.glob(path_pattern)
            if files:
                audio_file = files[0]
                print(f"âœ… æ‰¾åˆ°æµ‹è¯•éŸ³é¢‘: {audio_file}")
                return audio_file
        else:
            if os.path.exists(path_pattern):
                print(f"âœ… æ‰¾åˆ°æµ‹è¯•éŸ³é¢‘: {path_pattern}")
                return path_pattern
    
    print("âŒ æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶")
    return None

def test_whisperx_transcription(model, audio_file):
    """æµ‹è¯•WhisperXè½¬å½•"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯•4: WhisperXè½¬å½•")
    print("=" * 50)
    
    if not model or not audio_file:
        print("âŒ ç¼ºå°‘å¿…è¦å‚æ•°")
        return None
    
    try:
        print(f"ğŸµ è½¬å½•éŸ³é¢‘: {os.path.basename(audio_file)}")
        result = model.transcribe(audio_file, batch_size=16)
        
        print("âœ… è½¬å½•æˆåŠŸ!")
        print(f"ğŸ“‹ ç»“æœkeys: {list(result.keys())}")
        
        segments = result.get('segments', [])
        print(f"ğŸ“‹ segmentsæ•°é‡: {len(segments)}")
        
        if segments:
            first_seg = segments[0]
            print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªsegment keys: {list(first_seg.keys())}")
            print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªsegmentå†…å®¹: {first_seg.get('text', 'N/A')[:100]}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰wordså­—æ®µ
            if 'words' in first_seg:
                words = first_seg['words']
                print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªsegmentçš„wordsæ•°é‡: {len(words) if words else 0}")
                if words:
                    print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªword: {words[0]}")
        
        return result
        
    except Exception as e:
        print(f"âŒ è½¬å½•å¤±è´¥: {e}")
        print(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None

def test_whisperx_alignment(transcribe_result, align_model, metadata, audio_file):
    """æµ‹è¯•WhisperXå¯¹é½"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯•5: WhisperXå¯¹é½")
    print("=" * 50)
    
    if not all([transcribe_result, align_model, metadata, audio_file]):
        print("âŒ ç¼ºå°‘å¿…è¦å‚æ•°")
        return None
    
    try:
        import torch
        import whisperx
        
        segments = transcribe_result.get('segments', [])
        if not segments:
            print("âŒ æ²¡æœ‰segmentså¯ä»¥å¯¹é½")
            return None
        
        print(f"ğŸ¯ å¯¹é½ {len(segments)} ä¸ªsegments")
        device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # æ‰§è¡Œå¯¹é½
        aligned_result = whisperx.align(
            segments,
            align_model,
            metadata,
            audio_file,
            device,
            return_char_alignments=False
        )
        
        print("âœ… å¯¹é½æˆåŠŸ!")
        print(f"ğŸ“‹ å¯¹é½ç»“æœkeys: {list(aligned_result.keys())}")
        
        # è¯¦ç»†åˆ†æå¯¹é½ç»“æœ
        aligned_segments = aligned_result.get("segments", [])
        word_segments = aligned_result.get("word_segments", [])
        
        print(f"ğŸ“‹ å¯¹é½åsegmentsæ•°é‡: {len(aligned_segments)}")
        print(f"ğŸ“‹ word_segmentsæ•°é‡: {len(word_segments)}")
        
        # æ£€æŸ¥ç¬¬ä¸€ä¸ªå¯¹é½åçš„segment
        if aligned_segments:
            first_aligned = aligned_segments[0]
            print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªå¯¹é½segment keys: {list(first_aligned.keys())}")
            
            if 'words' in first_aligned and first_aligned['words']:
                words_in_segment = first_aligned['words']
                print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªsegmentä¸­çš„wordsæ•°é‡: {len(words_in_segment)}")
                print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªwordè¯¦æƒ…: {words_in_segment[0] if words_in_segment else 'N/A'}")
        
        return aligned_result
        
    except Exception as e:
        print(f"âŒ å¯¹é½å¤±è´¥: {e}")
        print(f"ğŸ“‹ é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return None

def test_data_extraction(aligned_result):
    """æµ‹è¯•æ•°æ®æå–"""
    print("\n" + "=" * 50)
    print("ğŸ” æµ‹è¯•6: æ•°æ®æå–åˆ†æ")
    print("=" * 50)
    
    if not aligned_result:
        print("âŒ æ²¡æœ‰å¯¹é½ç»“æœ")
        return
    
    # æ–¹æ³•1: ä»word_segmentsæå–
    word_segments = aligned_result.get("word_segments", [])
    print(f"ğŸ“‹ æ–¹æ³•1 - word_segments: {len(word_segments)} ä¸ªè¯")
    
    # æ–¹æ³•2: ä»segmentsä¸­çš„wordsæå–
    segments = aligned_result.get("segments", [])
    total_words_from_segments = 0
    
    for i, seg in enumerate(segments):
        words_in_seg = seg.get('words', [])
        if words_in_seg:
            total_words_from_segments += len(words_in_seg)
            if i == 0:  # æ˜¾ç¤ºç¬¬ä¸€ä¸ªçš„è¯¦æƒ…
                print(f"ğŸ“‹ ç¬¬ä¸€ä¸ªsegmentçš„wordsç¤ºä¾‹: {words_in_seg[0]}")
    
    print(f"ğŸ“‹ æ–¹æ³•2 - ä»segmentsæå–words: {total_words_from_segments} ä¸ªè¯")
    
    # åˆ†æå“ªç§æ–¹æ³•æœ‰æ•°æ®
    if word_segments:
        print("âœ… å»ºè®®ä½¿ç”¨: word_segmentså­—æ®µ")
        return word_segments
    elif total_words_from_segments > 0:
        print("âœ… å»ºè®®ä½¿ç”¨: segmentsä¸­çš„wordså­—æ®µ")
        words = []
        for seg in segments:
            if 'words' in seg and seg['words']:
                words.extend(seg['words'])
        return words
    else:
        print("âŒ ä¸¤ç§æ–¹æ³•éƒ½æ²¡æœ‰æ‰¾åˆ°è¯çº§æ•°æ®")
        return []

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å¼€å§‹WhisperXå…¨é¢æµ‹è¯•")
    print("ç›®æ ‡ï¼šæ‰¾å‡ºwordsä¸º0çš„æ ¹æœ¬åŸå› ")
    
    # æµ‹è¯•1: ä¾èµ–å¯¼å…¥
    if not test_imports():
        return
    
    # æµ‹è¯•2: WhisperXåŸºç¡€åŠŸèƒ½
    model, align_model, metadata = test_whisperx_basic()
    if not model:
        return
    
    # æµ‹è¯•3: æ‰¾åˆ°æµ‹è¯•éŸ³é¢‘
    audio_file = create_test_audio()
    if not audio_file:
        print("ğŸ’¡ è¯·å°†æµ‹è¯•éŸ³é¢‘æ–‡ä»¶æ”¾åœ¨ /shenglin/ComfyUI/input/ ç›®å½•ä¸‹")
        return
    
    # æµ‹è¯•4: è½¬å½•
    transcribe_result = test_whisperx_transcription(model, audio_file)
    if not transcribe_result:
        return
    
    # æµ‹è¯•5: å¯¹é½(å¦‚æœæœ‰å¯¹é½æ¨¡å‹)
    if align_model and metadata:
        aligned_result = test_whisperx_alignment(transcribe_result, align_model, metadata, audio_file)
        if aligned_result:
            # æµ‹è¯•6: æ•°æ®æå–
            words = test_data_extraction(aligned_result)
            
            print("\n" + "=" * 50)
            print("ğŸ‰ æµ‹è¯•å®Œæˆ - ç»“æœæ€»ç»“")
            print("=" * 50)
            print(f"âœ… æœ€ç»ˆæå–åˆ°çš„wordsæ•°é‡: {len(words)}")
            if words:
                print(f"âœ… ç¬¬ä¸€ä¸ªwordç¤ºä¾‹: {words[0]}")
                print("âœ… è¯çº§å¯¹é½æ•°æ®å¯ç”¨!")
            else:
                print("âŒ æœªèƒ½æå–åˆ°è¯çº§å¯¹é½æ•°æ®")
                print("ğŸ’¡ è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå­—å¹•æ¸²æŸ“æ²¡æœ‰æ•°æ®çš„åŸå› ")
        else:
            print("âŒ å¯¹é½æ­¥éª¤å¤±è´¥ï¼Œè¿™å¯èƒ½æ˜¯æ ¹æœ¬åŸå› ")
    else:
        print("âŒ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œæ— æ³•è¿›è¡Œå¯¹é½æµ‹è¯•")
        print("ğŸ’¡ è¿™å¯èƒ½æ˜¯wordsä¸º0çš„æ ¹æœ¬åŸå› ")

if __name__ == "__main__":
    main()