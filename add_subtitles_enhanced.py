"""
ComfyUI å¢å¼ºå­—å¹•æ·»åŠ èŠ‚ç‚¹
æ•´åˆ comfy_add_subtitles çš„é«˜çº§æ ·å¼åŠŸèƒ½
ä¸ç°æœ‰ add_subtitles_to_frames èŠ‚ç‚¹æ¥å£å…¼å®¹ï¼Œä½†åŠŸèƒ½æ›´å¼ºå¤§
"""

from PIL import ImageDraw, ImageFont, Image, ImageFilter
from .utils import tensor2pil, pil2tensor
import math
import os
import json
from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

FONT_DIR = os.path.join(os.path.dirname(__file__), "fonts")


class SubtitleStyle:
    """å­—å¹•æ ·å¼é…ç½®ç±»"""
    
    def __init__(self, 
                 font_color: str = "white",
                 font_family: str = "Roboto-Regular.ttf", 
                 font_size: int = 100,
                 outline_color: str = "black",
                 outline_width: int = 3,
                 shadow_color: str = "black", 
                 shadow_offset: Tuple[int, int] = (2, 2),
                 background_color: str = None,
                 background_opacity: float = 0.7,
                 gradient_colors: List[str] = None,
                 text_align: str = "center"):
        self.font_color = font_color
        self.font_family = font_family
        self.font_size = font_size
        self.outline_color = outline_color
        self.outline_width = outline_width
        self.shadow_color = shadow_color
        self.shadow_offset = shadow_offset
        self.background_color = background_color
        self.background_opacity = background_opacity
        self.gradient_colors = gradient_colors or []
        self.text_align = text_align


class AddSubtitlesEnhancedNode:
    """å¢å¼ºç‰ˆå­—å¹•æ·»åŠ èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–å¯ç”¨å­—ä½“
        try:
            available_fonts = [f for f in os.listdir(FONT_DIR) if f.endswith('.ttf')]
        except:
            available_fonts = ["Roboto-Regular.ttf"]
        
        return {
            "required": { 
                "images": ("IMAGE",),
                "alignment": ("whisper_alignment",),
                "video_fps": ("FLOAT", {
                    "default": 24.0,
                    "step": 1,
                    "display": "number"
                }),
            },
            "optional": {
                # åŸºç¡€æ ·å¼
                "font_family": (available_fonts, {"default": "Roboto-Regular.ttf"}),
                "font_size": ("INT", {
                    "default": 100,
                    "min": 20,
                    "max": 500,
                    "step": 5
                }),
                "font_color": ("STRING", {"default": "white"}),
                
                # ä½ç½®æ§åˆ¶
                "x_position": ("INT", {
                    "default": 100,
                    "step": 50
                }),
                "y_position": ("INT", {
                    "default": 100, 
                    "step": 50
                }),
                "center_x": ("BOOLEAN", {"default": True}),
                "center_y": ("BOOLEAN", {"default": True}),
                
                # é«˜çº§æ ·å¼
                "outline_color": ("STRING", {"default": "black"}),
                "outline_width": ("INT", {
                    "default": 3,
                    "min": 0,
                    "max": 20,
                    "step": 1
                }),
                "shadow_color": ("STRING", {"default": "gray"}),
                "shadow_offset_x": ("INT", {
                    "default": 2,
                    "min": -20,
                    "max": 20,
                    "step": 1
                }),
                "shadow_offset_y": ("INT", {
                    "default": 2,
                    "min": -20, 
                    "max": 20,
                    "step": 1
                }),
                
                # èƒŒæ™¯æ ·å¼
                "background_color": ("STRING", {"default": ""}),
                "background_opacity": ("FLOAT", {
                    "default": 0.7,
                    "min": 0.0,
                    "max": 1.0,
                    "step": 0.1
                }),
                "background_padding": ("INT", {
                    "default": 20,
                    "min": 0,
                    "max": 100,
                    "step": 5
                }),
                
                # æ¸å˜æ•ˆæœ
                "gradient_colors": ("STRING", {
                    "default": "",
                    "placeholder": "ä¾‹å¦‚: #FF0000,#00FF00,#0000FF"
                }),
                
                # æ–‡å­—æ•ˆæœ
                "text_align": (["left", "center", "right"], {"default": "center"}),
                "line_spacing": ("FLOAT", {
                    "default": 1.2,
                    "min": 0.5,
                    "max": 3.0,
                    "step": 0.1
                }),
                "max_width": ("INT", {
                    "default": 0,
                    "min": 0,
                    "max": 2000,
                    "tooltip": "æœ€å¤§æ–‡å­—å®½åº¦ï¼Œ0ä¸ºä¸é™åˆ¶"
                }),
                
                # åŠ¨ç”»æ•ˆæœ
                "fade_in_duration": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0,
                    "step": 0.1,
                    "tooltip": "æ·¡å…¥æ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                "fade_out_duration": ("FLOAT", {
                    "default": 0.0,
                    "min": 0.0,
                    "max": 2.0, 
                    "step": 0.1,
                    "tooltip": "æ·¡å‡ºæ—¶é—´ï¼ˆç§’ï¼‰"
                }),
                
                # é«˜çº§é€‰é¡¹
                "enable_emoji": ("BOOLEAN", {
                    "default": True,
                    "tooltip": "æ˜¯å¦å¯ç”¨emojiè¡¨æƒ…æ¸²æŸ“"
                }),
                "text_case": (["none", "upper", "lower", "title"], {
                    "default": "none",
                    "tooltip": "æ–‡å­—å¤§å°å†™è½¬æ¢"
                }),
            }
        }

    RETURN_TYPES = ("IMAGE", "MASK", "IMAGE", "subtitle_coord", "STRING")
    RETURN_NAMES = ("IMAGE", "MASK", "cropped_subtitles", "subtitle_coord", "render_log")
    FUNCTION = "add_subtitles_enhanced"
    CATEGORY = "å­—å¹•"

    def add_subtitles_enhanced(self, 
                             images,
                             alignment: List[Dict],
                             video_fps: float = 24.0,
                             font_family: str = "Roboto-Regular.ttf",
                             font_size: int = 100,
                             font_color: str = "white",
                             x_position: int = 100,
                             y_position: int = 100,
                             center_x: bool = True,
                             center_y: bool = True,
                             outline_color: str = "black",
                             outline_width: int = 3,
                             shadow_color: str = "gray",
                             shadow_offset_x: int = 2,
                             shadow_offset_y: int = 2,
                             background_color: str = "",
                             background_opacity: float = 0.7,
                             background_padding: int = 20,
                             gradient_colors: str = "",
                             text_align: str = "center",
                             line_spacing: float = 1.2,
                             max_width: int = 0,
                             fade_in_duration: float = 0.0,
                             fade_out_duration: float = 0.0,
                             enable_emoji: bool = True,
                             text_case: str = "none") -> Tuple:
        """
        å¢å¼ºç‰ˆå­—å¹•æ·»åŠ åŠŸèƒ½
        """
        log_messages = []
        
        try:
            # è½¬æ¢å›¾åƒæ ¼å¼
            pil_images = tensor2pil(images)
            log_messages.append(f"ğŸ“· å¤„ç†å›¾åƒæ•°é‡: {len(pil_images)}")
            log_messages.append(f"ğŸ¬ è§†é¢‘å¸§ç‡: {video_fps} fps")
            log_messages.append(f"ğŸ¯ å¯¹é½æ•°æ®: {len(alignment)} ä¸ªç‰‡æ®µ")
            
            # åˆ›å»ºå­—å¹•æ ·å¼
            style = SubtitleStyle(
                font_color=font_color,
                font_family=font_family,
                font_size=font_size,
                outline_color=outline_color,
                outline_width=outline_width,
                shadow_color=shadow_color,
                shadow_offset=(shadow_offset_x, shadow_offset_y),
                background_color=background_color if background_color else None,
                background_opacity=background_opacity,
                gradient_colors=self._parse_gradient_colors(gradient_colors),
                text_align=text_align
            )
            
            # åŠ è½½å­—ä½“
            try:
                font_path = os.path.join(FONT_DIR, font_family)
                font = ImageFont.truetype(font_path, font_size)
                log_messages.append(f"ğŸ”¤ å­—ä½“åŠ è½½æˆåŠŸ: {font_family}")
            except Exception as e:
                # ä½¿ç”¨é»˜è®¤å­—ä½“ä½œä¸ºåå¤‡
                font = ImageFont.load_default()
                log_messages.append(f"âš ï¸ å­—ä½“åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“: {e}")
            
            # åˆå§‹åŒ–è¾“å‡ºåˆ—è¡¨
            pil_images_with_text = []
            cropped_pil_images_with_text = []
            pil_images_masks = []
            subtitle_coord = []
            
            # å¤„ç†ç©ºå¯¹é½æƒ…å†µ
            if len(alignment) == 0:
                log_messages.append("âš ï¸ æ— å¯¹é½æ•°æ®ï¼Œè¿”å›åŸå§‹å›¾åƒ")
                return self._return_original_images(pil_images, log_messages)
            
            # å¤„ç†æ¯ä¸€å¸§
            last_frame_no = 0
            processed_segments = 0
            
            for i, alignment_obj in enumerate(alignment):
                start_time = alignment_obj.get("start", 0.0)
                end_time = alignment_obj.get("end", 0.0) 
                text = alignment_obj.get("value", "").strip()
                
                if not text:
                    continue
                
                # åº”ç”¨æ–‡å­—å¤§å°å†™è½¬æ¢
                text = self._apply_text_case(text, text_case)
                
                start_frame_no = math.floor(start_time * video_fps)
                end_frame_no = math.floor(end_time * video_fps)
                
                # ç¡®ä¿å¸§æ•°åœ¨æœ‰æ•ˆèŒƒå›´å†…
                start_frame_no = max(0, min(start_frame_no, len(pil_images) - 1))
                end_frame_no = max(start_frame_no, min(end_frame_no, len(pil_images)))
                
                # æ·»åŠ æ— å­—å¹•å¸§
                for frame_idx in range(last_frame_no, start_frame_no):
                    if frame_idx < len(pil_images):
                        self._add_empty_frame(
                            pil_images[frame_idx],
                            pil_images_with_text,
                            pil_images_masks,
                            cropped_pil_images_with_text,
                            subtitle_coord
                        )
                
                # æ·»åŠ æœ‰å­—å¹•å¸§
                for frame_idx in range(start_frame_no, end_frame_no):
                    if frame_idx < len(pil_images):
                        # è®¡ç®—åŠ¨ç”»é€æ˜åº¦
                        frame_time = frame_idx / video_fps
                        alpha = self._calculate_alpha(
                            frame_time, start_time, end_time,
                            fade_in_duration, fade_out_duration
                        )
                        
                        # æ¸²æŸ“å­—å¹•
                        self._render_subtitle_frame(
                            pil_images[frame_idx],
                            text,
                            font,
                            style,
                            x_position, y_position,
                            center_x, center_y,
                            max_width,
                            line_spacing,
                            alpha,
                            pil_images_with_text,
                            pil_images_masks,
                            cropped_pil_images_with_text,
                            subtitle_coord
                        )
                
                last_frame_no = end_frame_no
                processed_segments += 1
                
                log_messages.append(
                    f"âœ… ç‰‡æ®µ {i+1}: '{text[:20]}...' "
                    f"({start_time:.1f}s-{end_time:.1f}s, å¸§{start_frame_no}-{end_frame_no})"
                )
            
            # å¤„ç†å‰©ä½™å¸§
            for frame_idx in range(last_frame_no, len(pil_images)):
                self._add_empty_frame(
                    pil_images[frame_idx],
                    pil_images_with_text,
                    pil_images_masks, 
                    cropped_pil_images_with_text,
                    subtitle_coord
                )
            
            log_messages.append(f"ğŸ‰ å­—å¹•æ¸²æŸ“å®Œæˆ!")
            log_messages.append(f"ğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
            log_messages.append(f"  - å¤„ç†ç‰‡æ®µæ•°: {processed_segments}")
            log_messages.append(f"  - æ€»å¸§æ•°: {len(pil_images_with_text)}")
            log_messages.append(f"  - å­—å¹•å¸§æ•°: {sum(1 for coord in subtitle_coord if coord != (0,0,0,0))}")
            
            # è½¬æ¢å›å¼ é‡æ ¼å¼
            output_images = pil2tensor(pil_images_with_text)
            output_masks = pil2tensor([img.convert("L") for img in pil_images_masks])
            cropped_images = pil2tensor(cropped_pil_images_with_text)
            
            return (output_images, output_masks, cropped_images, subtitle_coord, "\n".join(log_messages))
            
        except Exception as e:
            error_msg = f"å­—å¹•æ¸²æŸ“è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            import traceback
            logger.error(traceback.format_exc())
            log_messages.append(f"âŒ {error_msg}")
            
            # è¿”å›åŸå§‹å›¾åƒ
            return self._return_original_images(pil_images, log_messages)
    
    def _parse_gradient_colors(self, gradient_str: str) -> List[str]:
        """è§£ææ¸å˜é¢œè‰²å­—ç¬¦ä¸²"""
        if not gradient_str.strip():
            return []
        
        try:
            colors = [color.strip() for color in gradient_str.split(',')]
            return [color for color in colors if color]
        except:
            return []
    
    def _apply_text_case(self, text: str, text_case: str) -> str:
        """åº”ç”¨æ–‡å­—å¤§å°å†™è½¬æ¢"""
        if text_case == "upper":
            return text.upper()
        elif text_case == "lower":
            return text.lower()
        elif text_case == "title":
            return text.title()
        return text
    
    def _calculate_alpha(self, frame_time: float, start_time: float, end_time: float,
                        fade_in_duration: float, fade_out_duration: float) -> float:
        """è®¡ç®—å¸§çš„é€æ˜åº¦ï¼ˆç”¨äºæ·¡å…¥æ·¡å‡ºæ•ˆæœï¼‰"""
        duration = end_time - start_time
        relative_time = frame_time - start_time
        
        alpha = 1.0
        
        # æ·¡å…¥æ•ˆæœ
        if fade_in_duration > 0 and relative_time < fade_in_duration:
            alpha *= relative_time / fade_in_duration
        
        # æ·¡å‡ºæ•ˆæœ  
        if fade_out_duration > 0 and relative_time > (duration - fade_out_duration):
            remaining_time = end_time - frame_time
            alpha *= remaining_time / fade_out_duration
        
        return max(0.0, min(1.0, alpha))
    
    def _add_empty_frame(self, img, images_with_text, masks, cropped_images, coords):
        """æ·»åŠ æ— å­—å¹•çš„å¸§"""
        img = img.convert("RGB")
        width, height = img.size
        
        images_with_text.append(img)
        
        # åˆ›å»ºé»‘è‰²è’™ç‰ˆ
        black_mask = Image.new('RGB', (width, height), 'black')
        masks.append(black_mask)
        
        # åˆ›å»ºæœ€å°å°ºå¯¸çš„è£å‰ªå›¾åƒ
        small_black = Image.new('RGB', (1, 1), 'black')
        cropped_images.append(small_black)
        
        coords.append((0, 0, 0, 0))
    
    def _render_subtitle_frame(self, img, text, font, style, x_pos, y_pos,
                              center_x, center_y, max_width, line_spacing, alpha,
                              images_with_text, masks, cropped_images, coords):
        """æ¸²æŸ“å•ä¸ªå­—å¹•å¸§"""
        img = img.convert("RGBA")
        width, height = img.size
        
        # åˆ›å»ºæ–‡å­—å±‚
        text_layer = Image.new('RGBA', (width, height), (0, 0, 0, 0))
        draw = ImageDraw.Draw(text_layer)
        
        # å¤„ç†æ¢è¡Œï¼ˆå¦‚æœæŒ‡å®šäº†æœ€å¤§å®½åº¦ï¼‰
        lines = self._wrap_text(text, font, max_width) if max_width > 0 else [text]
        
        # è®¡ç®—æ–‡å­—æ€»ä½“å°ºå¯¸
        line_heights = []
        line_widths = []
        for line in lines:
            bbox = draw.textbbox((0, 0), line, font=font)
            line_widths.append(bbox[2] - bbox[0])
            line_heights.append(bbox[3] - bbox[1])
        
        total_height = sum(line_heights) + (len(lines) - 1) * int(line_heights[0] * (line_spacing - 1))
        max_line_width = max(line_widths) if line_widths else 0
        
        # è®¡ç®—èµ·å§‹ä½ç½®
        if center_x:
            start_x = (width - max_line_width) // 2
        else:
            start_x = x_pos
            
        if center_y:
            start_y = (height - total_height) // 2
        else:
            start_y = y_pos
        
        # ç»˜åˆ¶èƒŒæ™¯ï¼ˆå¦‚æœæœ‰ï¼‰
        if style.background_color:
            bg_alpha = int(255 * style.background_opacity * alpha)
            bg_color = self._parse_color(style.background_color) + (bg_alpha,)
            
            # è®¡ç®—èƒŒæ™¯çŸ©å½¢
            padding = 20  # èƒŒæ™¯å†…è¾¹è·
            bg_left = start_x - padding
            bg_top = start_y - padding
            bg_right = start_x + max_line_width + padding
            bg_bottom = start_y + total_height + padding
            
            draw.rectangle([bg_left, bg_top, bg_right, bg_bottom], fill=bg_color)
        
        # ç»˜åˆ¶æ¯è¡Œæ–‡å­—
        current_y = start_y
        text_coords = []
        
        for i, line in enumerate(lines):
            if not line.strip():
                current_y += int(line_heights[0] * line_spacing)
                continue
                
            # è®¡ç®—è¯¥è¡Œçš„xä½ç½®
            line_width = line_widths[i]
            if style.text_align == "center":
                line_x = start_x + (max_line_width - line_width) // 2
            elif style.text_align == "right":
                line_x = start_x + max_line_width - line_width
            else:  # left
                line_x = start_x
            
            # ç»˜åˆ¶é˜´å½±
            if style.shadow_color and style.shadow_offset != (0, 0):
                shadow_x = line_x + style.shadow_offset[0]
                shadow_y = current_y + style.shadow_offset[1]
                shadow_color = self._parse_color(style.shadow_color) + (int(255 * alpha),)
                draw.text((shadow_x, shadow_y), line, font=font, fill=shadow_color)
            
            # ç»˜åˆ¶æè¾¹
            if style.outline_width > 0:
                outline_color = self._parse_color(style.outline_color) + (int(255 * alpha),)
                for dx in range(-style.outline_width, style.outline_width + 1):
                    for dy in range(-style.outline_width, style.outline_width + 1):
                        if dx != 0 or dy != 0:
                            draw.text((line_x + dx, current_y + dy), line, 
                                    font=font, fill=outline_color)
            
            # ç»˜åˆ¶ä¸»æ–‡å­—
            text_color = self._parse_color(style.font_color) + (int(255 * alpha),)
            draw.text((line_x, current_y), line, font=font, fill=text_color)
            
            # è®°å½•åæ ‡
            bbox = draw.textbbox((line_x, current_y), line, font=font)
            text_coords.append(bbox)
            
            current_y += int(line_heights[i] * line_spacing)
        
        # åˆå¹¶å›¾å±‚
        result_img = Image.alpha_composite(img, text_layer)
        result_img = result_img.convert("RGB")
        
        images_with_text.append(result_img)
        
        # åˆ›å»ºè’™ç‰ˆ
        mask = Image.new('L', (width, height), 0)
        mask_draw = ImageDraw.Draw(mask)
        
        # åœ¨è’™ç‰ˆä¸Šç»˜åˆ¶æ–‡å­—åŒºåŸŸ
        for bbox in text_coords:
            mask_draw.rectangle(bbox, fill=255)
        
        masks.append(mask.convert("RGB"))
        
        # åˆ›å»ºè£å‰ªçš„å­—å¹•å›¾åƒ
        if text_coords:
            # è®¡ç®—æ‰€æœ‰æ–‡å­—çš„è¾¹ç•Œæ¡†
            min_x = min(bbox[0] for bbox in text_coords)
            min_y = min(bbox[1] for bbox in text_coords) 
            max_x = max(bbox[2] for bbox in text_coords)
            max_y = max(bbox[3] for bbox in text_coords)
            
            # è£å‰ªå­—å¹•åŒºåŸŸ
            cropped_subtitle = result_img.crop((min_x, min_y, max_x, max_y))
            cropped_images.append(cropped_subtitle)
            coords.append((min_x, min_y, max_x, max_y))
        else:
            # æ— æ–‡å­—æ—¶æ·»åŠ å°é»‘å›¾
            small_black = Image.new('RGB', (1, 1), 'black')
            cropped_images.append(small_black)
            coords.append((0, 0, 0, 0))
    
    def _wrap_text(self, text: str, font, max_width: int) -> List[str]:
        """æ–‡å­—æ¢è¡Œå¤„ç†"""
        if max_width <= 0:
            return [text]
        
        words = text.split()
        lines = []
        current_line = []
        
        draw = ImageDraw.Draw(Image.new('RGB', (1, 1)))
        
        for word in words:
            test_line = " ".join(current_line + [word])
            bbox = draw.textbbox((0, 0), test_line, font=font)
            width = bbox[2] - bbox[0]
            
            if width <= max_width or not current_line:
                current_line.append(word)
            else:
                lines.append(" ".join(current_line))
                current_line = [word]
        
        if current_line:
            lines.append(" ".join(current_line))
        
        return lines
    
    def _parse_color(self, color_str: str) -> Tuple[int, int, int]:
        """è§£æé¢œè‰²å­—ç¬¦ä¸²ä¸ºRGBå…ƒç»„"""
        color_str = color_str.strip().lower()
        
        # é¢„å®šä¹‰é¢œè‰²
        color_map = {
            'white': (255, 255, 255),
            'black': (0, 0, 0),
            'red': (255, 0, 0),
            'green': (0, 255, 0),
            'blue': (0, 0, 255),
            'yellow': (255, 255, 0),
            'cyan': (0, 255, 255),
            'magenta': (255, 0, 255),
            'gray': (128, 128, 128),
            'grey': (128, 128, 128),
        }
        
        if color_str in color_map:
            return color_map[color_str]
        
        # å¤„ç†åå…­è¿›åˆ¶é¢œè‰²
        if color_str.startswith('#'):
            try:
                hex_str = color_str[1:]
                if len(hex_str) == 6:
                    return tuple(int(hex_str[i:i+2], 16) for i in (0, 2, 4))
                elif len(hex_str) == 3:
                    return tuple(int(hex_str[i]*2, 16) for i in range(3))
            except ValueError:
                pass
        
        # å¤„ç†RGBæ ¼å¼ rgb(255,255,255)
        if color_str.startswith('rgb(') and color_str.endswith(')'):
            try:
                rgb_str = color_str[4:-1]
                return tuple(int(x.strip()) for x in rgb_str.split(','))
            except ValueError:
                pass
        
        # é»˜è®¤è¿”å›ç™½è‰²
        return (255, 255, 255)
    
    def _return_original_images(self, pil_images, log_messages):
        """è¿”å›åŸå§‹å›¾åƒï¼ˆé”™è¯¯å¤„ç†æ—¶ä½¿ç”¨ï¼‰"""
        # åˆ›å»ºç©ºè’™ç‰ˆå’Œåæ ‡
        width, height = pil_images[0].size if pil_images else (1, 1)
        black_masks = [Image.new('RGB', (width, height), 'black') for _ in pil_images]
        small_blacks = [Image.new('RGB', (1, 1), 'black') for _ in pil_images]
        empty_coords = [(0, 0, 0, 0) for _ in pil_images]
        
        output_images = pil2tensor(pil_images)
        output_masks = pil2tensor([img.convert("L") for img in black_masks])
        cropped_images = pil2tensor(small_blacks)
        
        return (output_images, output_masks, cropped_images, empty_coords, "\n".join(log_messages))


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "AddSubtitlesEnhancedNode": AddSubtitlesEnhancedNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AddSubtitlesEnhancedNode": "Add Subtitles (Enhanced)"
}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸ¨ å¢å¼ºå­—å¹•æ·»åŠ èŠ‚ç‚¹æµ‹è¯•")
    node = AddSubtitlesEnhancedNode()
    print("ğŸ“‹ è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
    print("ğŸ¯ è¿”å›ç±»å‹:", node.RETURN_TYPES)
    print("ğŸ“ è¿”å›åç§°:", node.RETURN_NAMES)