"""
ComfyUI WhisperX å¼ºåˆ¶å¯¹é½èŠ‚ç‚¹
ä¸ç°æœ‰ apply_whisper èŠ‚ç‚¹æ¥å£ä¿æŒä¸€è‡´ï¼Œæ”¯æŒéŸ³é¢‘æµè¾“å…¥
ç”¨äºå°†å‡†ç¡®æ–‡æœ¬ä¸éŸ³é¢‘è¿›è¡Œç²¾ç¡®æ—¶é—´åŒæ­¥ï¼Œç”Ÿæˆé«˜è´¨é‡å­—å¹•
"""

import os
import sys
import json
import uuid
import tempfile
import torchaudio
import torch
import logging
import folder_paths
from typing import Dict, Any, Tuple, Optional, List

import comfy.model_management as mm
import comfy.model_patcher

logger = logging.getLogger(__name__)

# WhisperXä¾èµ–æ£€æŸ¥
try:
    import whisperx
    WHISPERX_AVAILABLE = True
    logger.info(f"WhisperXç‰ˆæœ¬: {whisperx.__version__ if hasattr(whisperx, '__version__') else 'Unknown'}")
except ImportError as e:
    WHISPERX_AVAILABLE = False
    whisperx = None
    logger.warning(f"WhisperXæœªå®‰è£…: {e}")

try:
    import ctranslate2
    logger.info(f"CTranslate2ç‰ˆæœ¬: {ctranslate2.__version__ if hasattr(ctranslate2, '__version__') else 'Unknown'}")
except ImportError:
    logger.warning("CTranslate2æœªå®‰è£…ï¼Œå¯èƒ½å¯¼è‡´WhisperXåŠŸèƒ½å¼‚å¸¸")

WHISPERX_MODEL_SUBDIR = os.path.join("stt", "whisperx")
WHISPERX_PATCHER_CACHE = {}


def convert_device_for_whisperx(device):
    """å°†torchè®¾å¤‡æ ¼å¼è½¬æ¢ä¸ºWhisperXå…¼å®¹çš„è®¾å¤‡å­—ç¬¦ä¸²ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if hasattr(device, 'type'):
        device_type = device.type
    else:
        device_str = str(device).lower()
        if 'cuda' in device_str:
            device_type = 'cuda'
        elif 'cpu' in device_str:
            device_type = 'cpu'
        else:
            device_type = 'cpu'  # é»˜è®¤ä½¿ç”¨CPU
    
    # WhisperXåªæ”¯æŒ 'cuda' æˆ– 'cpu'ï¼Œä¸æ”¯æŒ 'cuda:0' æ ¼å¼
    if device_type == 'cuda':
        return 'cuda'
    else:
        return 'cpu'


def validate_device_compatibility(device_str: str) -> bool:
    """éªŒè¯è®¾å¤‡å…¼å®¹æ€§ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if device_str not in ['cuda', 'cpu']:
        logger.warning(f"è®¾å¤‡ '{device_str}' å¯èƒ½ä¸è¢«WhisperXæ”¯æŒï¼Œå·²è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼")
        return False
    
    if device_str == 'cuda' and torch and not torch.cuda.is_available():
        logger.warning("CUDAè®¾å¤‡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False
    
    return True


class WhisperXModelWrapper(torch.nn.Module):
    """WhisperXæ¨¡å‹åŒ…è£…å™¨ï¼Œé›†æˆComfyUIæ¨¡å‹ç®¡ç†"""
    
    def __init__(self, model_name, language=None):
        super().__init__()
        self.model_name = model_name
        self.language = language
        self.whisperx_model = None
        self.align_model = None
        self.model_loaded_weight_memory = 0
        self.device = mm.get_torch_device()
        self.compute_type = "float16" if self.device.type == "cuda" else "int8"

    def load_model(self, device):
        """åŠ è½½WhisperXæ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡"""
        if not WHISPERX_AVAILABLE:
            raise ImportError("WhisperX not installed. Please run: pip install whisperx")
        
        try:
            # è½¬æ¢è®¾å¤‡æ ¼å¼ï¼štorch.device -> WhisperXå…¼å®¹æ ¼å¼
            device_str = convert_device_for_whisperx(device)
            
            # éªŒè¯è®¾å¤‡å…¼å®¹æ€§
            if not validate_device_compatibility(device_str):
                if device_str == 'cuda':
                    device_str = 'cpu'  # å›é€€åˆ°CPU
                    logger.info("CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
            
            logger.info(f"Loading WhisperX model with device: {device_str}")
            
            # åŠ è½½Whisper ASRæ¨¡å‹
            self.whisperx_model = whisperx.load_model(
                self.model_name,
                device_str,  # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼çš„è®¾å¤‡
                compute_type=self.compute_type,
                language=self.language if self.language != "auto" else None
            )
            
            # ä¼°ç®—æ¨¡å‹å¤§å°ç”¨äºå†…å­˜ç®¡ç†
            if hasattr(self.whisperx_model, 'model'):
                model_size = sum(p.numel() * p.element_size() 
                               for p in self.whisperx_model.model.parameters())
                self.model_loaded_weight_memory = model_size
            
            logger.info(f"WhisperX model '{self.model_name}' loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to load WhisperX model: {e}")
            raise


class WhisperXPatcher(comfy.model_patcher.ModelPatcher):
    """WhisperXæ¨¡å‹ç®¡ç†å™¨ï¼Œé›†æˆComfyUIå†…å­˜ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, model, *args, **kwargs):
        super().__init__(model, *args, **kwargs)

    def patch_model(self, device_to=None, *args, **kwargs):
        """åŠ è½½æ¨¡å‹åˆ°ç›®æ ‡è®¾å¤‡"""
        target_device = self.load_device

        if self.model.whisperx_model is None:
            logger.info(f"Loading WhisperX model '{self.model.model_name}' to {target_device}...")
            self.model.load_model(target_device)
            self.size = self.model.model_loaded_weight_memory
        else:
            logger.info(f"WhisperX model '{self.model.model_name}' already loaded")

        return super().patch_model(device_to=target_device, *args, **kwargs)

    def unpatch_model(self, device_to=None, unpatch_weights=True, *args, **kwargs):
        """å¸è½½æ¨¡å‹é‡Šæ”¾æ˜¾å­˜"""
        if unpatch_weights:
            logger.info(f"Unloading WhisperX model '{self.model.model_name}'...")
            self.model.whisperx_model = None
            self.model.align_model = None
            self.model.model_loaded_weight_memory = 0
            mm.soft_empty_cache()
        
        return super().unpatch_model(device_to, unpatch_weights, *args, **kwargs)


class ApplyWhisperXAlignmentNode:
    """WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–æ”¯æŒçš„è¯­è¨€é€‰é¡¹
        language_options = [
            "auto",      # è‡ªåŠ¨æ£€æµ‹
            "Chinese",   # ä¸­æ–‡
            "English",   # è‹±è¯­  
            "Japanese",  # æ—¥è¯­
            "Korean",    # éŸ©è¯­
            "French",    # æ³•è¯­
            "German",    # å¾·è¯­
            "Spanish",   # è¥¿ç­ç‰™è¯­
            "Italian"    # æ„å¤§åˆ©è¯­
        ]
        
        # æ¨¡å‹å¤§å°é€‰é¡¹
        model_options = [
            'tiny', 'base', 'small', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large'
        ]
        
        return {
            "required": {
                "audio": ("AUDIO",),  # ä¸apply_whisperä¿æŒä¸€è‡´
                "reference_text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "è¾“å…¥å‡†ç¡®çš„æ–‡æœ¬å†…å®¹ï¼Œå°†ä¸éŸ³é¢‘è¿›è¡Œå¼ºåˆ¶å¯¹é½"
                }),
                "model": (model_options, {"default": "base"}),
            },
            "optional": {
                "language": (language_options, {"default": "auto"}),
                "return_char_alignments": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦è¿”å›å­—ç¬¦çº§åˆ«çš„å¯¹é½ä¿¡æ¯"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "whisper_alignment", "whisper_alignment", "STRING")
    RETURN_NAMES = ("aligned_text", "segments_alignment", "words_alignment", "process_log")
    FUNCTION = "apply_whisperx_alignment"
    CATEGORY = "å­—å¹•"

    def apply_whisperx_alignment(self, 
                               audio: Dict[str, torch.Tensor],
                               reference_text: str,
                               model: str,
                               language: str = "auto",
                               return_char_alignments: bool = False) -> Tuple[str, List[Dict], List[Dict], str]:
        """
        æ‰§è¡ŒWhisperXå¼ºåˆ¶å¯¹é½
        
        Args:
            audio: éŸ³é¢‘å¼ é‡å­—å…¸ {"waveform": tensor, "sample_rate": int}
            reference_text: å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬
            model: æ¨¡å‹å¤§å°
            language: è¯­è¨€ï¼ˆautoä¸ºè‡ªåŠ¨æ£€æµ‹ï¼‰
            return_char_alignments: æ˜¯å¦è¿”å›å­—ç¬¦çº§å¯¹é½
            
        Returns:
            (å¯¹é½æ–‡æœ¬, å¥çº§å¯¹é½, è¯çº§å¯¹é½, å¤„ç†æ—¥å¿—)
        """
        log_messages = []
        
        try:
            # éªŒè¯è¾“å…¥
            if not reference_text.strip():
                error_msg = "è¯·æä¾›å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬ç”¨äºå¯¹é½"
                log_messages.append(f"âŒ {error_msg}")
                return "", [], [], "\n".join(log_messages)
            
            log_messages.append(f"ğŸ“ å‚è€ƒæ–‡æœ¬é•¿åº¦: {len(reference_text)} å­—ç¬¦")
            log_messages.append(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
            log_messages.append(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = folder_paths.get_temp_directory()
            os.makedirs(temp_dir, exist_ok=True)
            audio_save_path = os.path.join(temp_dir, f"whisperx_{uuid.uuid1()}.wav")
            
            torchaudio.save(
                audio_save_path, 
                audio['waveform'].squeeze(0), 
                audio["sample_rate"]
            )
            log_messages.append(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {os.path.basename(audio_save_path)}")
            
            # è·å–æˆ–åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
            language_code = self._get_language_code(language)
            cache_key = f"{model}_{language_code}"
            
            if cache_key not in WHISPERX_PATCHER_CACHE:
                load_device = mm.get_torch_device()
                log_messages.append(f"ğŸ”„ åˆå§‹åŒ–WhisperXæ¨¡å‹ç®¡ç†å™¨: {model}")
                
                model_wrapper = WhisperXModelWrapper(model, language_code)
                patcher = WhisperXPatcher(
                    model=model_wrapper,
                    load_device=load_device,
                    offload_device=mm.unet_offload_device(),
                    size=0  # å°†åœ¨æ¨¡å‹åŠ è½½æ—¶è®¾ç½®
                )
                WHISPERX_PATCHER_CACHE[cache_key] = patcher
            
            patcher = WHISPERX_PATCHER_CACHE[cache_key]
            
            # åŠ è½½æ¨¡å‹
            mm.load_model_gpu(patcher)
            whisperx_model = patcher.model.whisperx_model
            
            if whisperx_model is None:
                error_msg = f"WhisperXæ¨¡å‹åŠ è½½å¤±è´¥: {model}"
                log_messages.append(f"âŒ {error_msg}")
                raise RuntimeError(error_msg)
            
            log_messages.append("âœ… WhisperXæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # æ‰§è¡Œè½¬å½•ï¼ˆè·å–åˆå§‹å¯¹é½ï¼‰
            log_messages.append("ğŸµ å¼€å§‹éŸ³é¢‘è½¬å½•...")
            transcribe_options = {}
            if language_code and language_code != "auto":
                transcribe_options['language'] = language_code
            
            audio_result = whisperx_model.transcribe(
                audio_save_path, 
                batch_size=16,
                **transcribe_options
            )
            
            detected_language = audio_result.get("language", language_code or "unknown")
            log_messages.append(f"ğŸ” æ£€æµ‹åˆ°è¯­è¨€: {detected_language}")
            
            # åŠ è½½å¯¹é½æ¨¡å‹
            log_messages.append("ğŸ¯ åŠ è½½å¯¹é½æ¨¡å‹...")
            try:
                # è½¬æ¢è®¾å¤‡æ ¼å¼ç”¨äºå¯¹é½æ¨¡å‹
                align_device = convert_device_for_whisperx(patcher.load_device)
                model_a, metadata = whisperx.load_align_model(
                    language_code=detected_language,
                    device=align_device
                )
                patcher.model.align_model = model_a
                log_messages.append("âœ… å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                log_messages.append(f"âš ï¸ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€å¯¹é½: {e}")
                model_a, metadata = None, {}
            
            # æ‰§è¡Œå¼ºåˆ¶å¯¹é½
            log_messages.append("âš¡ å¼€å§‹å¼ºåˆ¶å¯¹é½...")
            if model_a is not None:
                aligned_result = whisperx.align(
                    audio_result["segments"],
                    model_a,
                    metadata,
                    audio_save_path,
                    align_device,  # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼çš„è®¾å¤‡
                    return_char_alignments=return_char_alignments
                )
                segments = aligned_result["segments"]
                words = aligned_result.get("word_segments", [])
            else:
                # ä½¿ç”¨åŸºç¡€è½¬å½•ç»“æœ
                segments = audio_result["segments"]
                words = []
                for segment in segments:
                    if "words" in segment:
                        words.extend(segment["words"])
            
            log_messages.append(f"ğŸ‰ å¯¹é½å®Œæˆ! å¥å­: {len(segments)}, è¯è¯­: {len(words)}")
            
            # æ ¼å¼åŒ–è¾“å‡ºä¸ºwhisper_alignmentæ ¼å¼
            segments_alignment = []
            words_alignment = []
            aligned_text_parts = []
            
            for segment in segments:
                # å¥çº§åˆ«å¯¹é½
                segment_data = {
                    "start": segment.get("start", 0.0),
                    "end": segment.get("end", 0.0),
                    "value": segment.get("text", "").strip(),
                    "confidence": segment.get("confidence", 1.0)
                }
                segments_alignment.append(segment_data)
                aligned_text_parts.append(segment_data["value"])
                
                # è¯çº§åˆ«å¯¹é½
                if "words" in segment:
                    for word in segment["words"]:
                        word_data = {
                            "start": word.get("start", segment_data["start"]),
                            "end": word.get("end", segment_data["end"]),
                            "value": word.get("word", "").strip(),
                            "confidence": word.get("confidence", 1.0)
                        }
                        words_alignment.append(word_data)
            
            # ç”Ÿæˆå¯¹é½åçš„å®Œæ•´æ–‡æœ¬
            aligned_text = " ".join(aligned_text_parts)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(audio_save_path)
                log_messages.append("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                log_messages.append(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
            
            log_messages.append(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            log_messages.append(f"  - å¯¹é½å¥å­æ•°: {len(segments_alignment)}")
            log_messages.append(f"  - å¯¹é½è¯è¯­æ•°: {len(words_alignment)}")
            log_messages.append(f"  - æ£€æµ‹è¯­è¨€: {detected_language}")
            log_messages.append(f"  - æ–‡æœ¬åŒ¹é…åº¦: {self._calculate_text_similarity(reference_text, aligned_text):.1%}")
            
            return aligned_text, segments_alignment, words_alignment, "\n".join(log_messages)
            
        except Exception as e:
            error_msg = f"WhisperXå¯¹é½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            import traceback
            logger.error(traceback.format_exc())
            
            # æä¾›å…·ä½“çš„é”™è¯¯åˆ†æå’Œè§£å†³å»ºè®®
            error_analysis = self._analyze_error(str(e))
            log_messages.append(f"âŒ {error_msg}")
            if error_analysis:
                log_messages.extend(error_analysis)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'audio_save_path' in locals():
                    os.remove(audio_save_path)
            except:
                pass
            
            return "", [], [], "\n".join(log_messages)
    
    def _get_language_code(self, language: str) -> str:
        """å°†è¯­è¨€åç§°è½¬æ¢ä¸ºä»£ç """
        language_mapping = {
            "auto": None,
            "chinese": "zh",
            "english": "en", 
            "japanese": "ja",
            "korean": "ko",
            "french": "fr",
            "german": "de", 
            "spanish": "es",
            "italian": "it"
        }
        return language_mapping.get(language.lower(), None)
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„è¯è¯­é‡å ç‡è®¡ç®—
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _analyze_error(self, error_str: str) -> List[str]:
        """åˆ†æé”™è¯¯å¹¶æä¾›è§£å†³å»ºè®®"""
        suggestions = []
        
        if "incompatible constructor arguments" in error_str and "ctranslate2" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°CTranslate2ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ›´æ–°WhisperX: pip install --upgrade whisperx",
                "   2. æˆ–é™çº§CTranslate2: pip install ctranslate2==3.24.0", 
                "   3. æˆ–ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬: pip install whisperx==3.1.1",
                "   4. æ£€æŸ¥CUDAç‰ˆæœ¬å…¼å®¹æ€§"
            ])
        
        elif "unsupported device" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡æ ¼å¼ä¸å…¼å®¹é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. å·²è‡ªåŠ¨ä¿®å¤è®¾å¤‡æ ¼å¼è½¬æ¢",
                "   2. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•é‡å¯ComfyUI",
                "   3. æ£€æŸ¥CUDAé©±åŠ¨æ˜¯å¦æ­£å¸¸å·¥ä½œ",
                "   4. å°è¯•ä½¿ç”¨CPUæ¨¡å¼æµ‹è¯•"
            ])
        
        elif "device" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡ç›¸å…³é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥CUDAæ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. å°è¯•ä½¿ç”¨CPUæ¨¡å¼",
                "   3. é‡å¯ComfyUIé‡æ–°åˆå§‹åŒ–è®¾å¤‡"
            ])
        
        elif "memory" in error_str.lower() or "oom" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°å†…å­˜ä¸è¶³ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (å¦‚ baseã€small)",
                "   2. é™ä½batch_size",
                "   3. å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„ç¨‹åº"
            ])
        
        elif "model" in error_str.lower() and "load" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹åŠ è½½é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "   2. æ¸…ç†æ¨¡å‹ç¼“å­˜ç›®å½•",
                "   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶"
            ])
        
        else:
            suggestions.extend([
                "ğŸ”§ é€šç”¨è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. é‡å¯ComfyUI",
                "   3. æŸ¥çœ‹å®Œæ•´é”™è¯¯æ—¥å¿—",
                "   4. å°è¯•ä½¿ç”¨è¾ƒå°çš„éŸ³é¢‘æ–‡ä»¶æµ‹è¯•"
            ])
        
        return suggestions


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": ApplyWhisperXAlignmentNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": "Apply WhisperX (Force Alignment)"
}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸµ WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹æµ‹è¯•")
    node = ApplyWhisperXAlignmentNode()
    print("ğŸ“‹ è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
    print("ğŸ¯ è¿”å›ç±»å‹:", node.RETURN_TYPES)
    print("ğŸ“ è¿”å›åç§°:", node.RETURN_NAMES)