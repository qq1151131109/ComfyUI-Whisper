"""
ComfyUI WhisperX å¼ºåˆ¶å¯¹é½èŠ‚ç‚¹
ä¸ç°æœ‰ apply_whisper èŠ‚ç‚¹æ¥å£ä¿æŒä¸€è‡´ï¼Œæ”¯æŒéŸ³é¢‘æµè¾“å…¥
ç”¨äºå°†å‡†ç¡®æ–‡æœ¬ä¸éŸ³é¢‘è¿›è¡Œç²¾ç¡®æ—¶é—´åŒæ­¥ï¼Œç”Ÿæˆé«˜è´¨é‡å­—å¹•
"""

import os
import sys
import json
import uuid
import tempfile
import torchaudio
import torch
import logging
import folder_paths
from typing import Dict, Any, Tuple, Optional, List

import comfy.model_management as mm
import comfy.model_patcher

logger = logging.getLogger(__name__)

# WhisperXä¾èµ–æ£€æŸ¥
try:
    import whisperx
    WHISPERX_AVAILABLE = True
    logger.info(f"WhisperXç‰ˆæœ¬: {whisperx.__version__ if hasattr(whisperx, '__version__') else 'Unknown'}")
except ImportError as e:
    WHISPERX_AVAILABLE = False
    whisperx = None
    logger.warning(f"WhisperXæœªå®‰è£…: {e}")

try:
    import ctranslate2
    logger.info(f"CTranslate2ç‰ˆæœ¬: {ctranslate2.__version__ if hasattr(ctranslate2, '__version__') else 'Unknown'}")
except ImportError:
    logger.warning("CTranslate2æœªå®‰è£…ï¼Œå¯èƒ½å¯¼è‡´WhisperXåŠŸèƒ½å¼‚å¸¸")

WHISPERX_MODEL_SUBDIR = os.path.join("stt", "whisperx")
WHISPERX_PATCHER_CACHE = {}


def convert_device_for_whisperx(device):
    """å°†torchè®¾å¤‡æ ¼å¼è½¬æ¢ä¸ºWhisperXå…¼å®¹çš„è®¾å¤‡å­—ç¬¦ä¸²ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if hasattr(device, 'type'):
        device_type = device.type
    else:
        device_str = str(device).lower()
        if 'cuda' in device_str:
            device_type = 'cuda'
        elif 'cpu' in device_str:
            device_type = 'cpu'
        else:
            device_type = 'cpu'  # é»˜è®¤ä½¿ç”¨CPU
    
    # WhisperXåªæ”¯æŒ 'cuda' æˆ– 'cpu'ï¼Œä¸æ”¯æŒ 'cuda:0' æ ¼å¼
    if device_type == 'cuda':
        return 'cuda'
    else:
        return 'cpu'


def validate_device_compatibility(device_str: str) -> bool:
    """éªŒè¯è®¾å¤‡å…¼å®¹æ€§ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if device_str not in ['cuda', 'cpu']:
        logger.warning(f"è®¾å¤‡ '{device_str}' å¯èƒ½ä¸è¢«WhisperXæ”¯æŒï¼Œå·²è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼")
        return False
    
    if device_str == 'cuda' and torch and not torch.cuda.is_available():
        logger.warning("CUDAè®¾å¤‡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False
    
    return True


class WhisperXModelWrapper(torch.nn.Module):
    """WhisperXæ¨¡å‹åŒ…è£…å™¨ï¼Œé›†æˆComfyUIæ¨¡å‹ç®¡ç†"""
    
    def __init__(self, model_name, language=None):
        super().__init__()
        self.model_name = model_name
        self.language = language
        self.whisperx_model = None
        self.align_model = None
        self.model_loaded_weight_memory = 0
        self.device = mm.get_torch_device()
        self.compute_type = "float16" if self.device.type == "cuda" else "int8"

    def load_model(self, device):
        """åŠ è½½WhisperXæ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡"""
        if not WHISPERX_AVAILABLE:
            raise ImportError("WhisperX not installed. Please run: pip install whisperx")
        
        try:
            # è½¬æ¢è®¾å¤‡æ ¼å¼ï¼štorch.device -> WhisperXå…¼å®¹æ ¼å¼
            device_str = convert_device_for_whisperx(device)
            
            # éªŒè¯è®¾å¤‡å…¼å®¹æ€§
            if not validate_device_compatibility(device_str):
                if device_str == 'cuda':
                    device_str = 'cpu'  # å›é€€åˆ°CPU
                    logger.info("CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
            
            logger.info(f"Loading WhisperX model with device: {device_str}")
            
            # åŠ è½½Whisper ASRæ¨¡å‹
            self.whisperx_model = whisperx.load_model(
                self.model_name,
                device_str,  # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼çš„è®¾å¤‡
                compute_type=self.compute_type,
                language=self.language if self.language != "auto" else None
            )
            
            # ä¼°ç®—æ¨¡å‹å¤§å°ç”¨äºå†…å­˜ç®¡ç†
            self.model_loaded_weight_memory = self._estimate_model_size()
            
            logger.info(f"WhisperX model '{self.model_name}' loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to load WhisperX model: {e}")
            raise
    
    def _estimate_model_size(self):
        """å®‰å…¨ä¼°ç®—WhisperXæ¨¡å‹å¤§å°"""
        try:
            # å°è¯•å¤šç§æ–¹æ³•ä¼°ç®—æ¨¡å‹å¤§å°
            if hasattr(self.whisperx_model, 'model') and hasattr(self.whisperx_model.model, 'parameters'):
                # æ ‡å‡†PyTorchæ¨¡å‹
                size = sum(p.numel() * p.element_size() for p in self.whisperx_model.model.parameters())
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {size / (1024*1024):.1f} MB (é€šè¿‡parameters)")
                return size
            elif hasattr(self.whisperx_model, 'model') and hasattr(self.whisperx_model.model, 'get_memory_stats'):
                # CTranslate2æ¨¡å‹
                stats = self.whisperx_model.model.get_memory_stats()
                size = stats.get('model_size', 0)
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {size / (1024*1024):.1f} MB (é€šè¿‡memory_stats)")
                return size
            else:
                # æ ¹æ®æ¨¡å‹åç§°ä¼°ç®—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                model_sizes = {
                    'tiny': 150 * 1024 * 1024,      # ~150MB
                    'base': 280 * 1024 * 1024,      # ~280MB  
                    'small': 970 * 1024 * 1024,     # ~970MB
                    'medium': 1940 * 1024 * 1024,   # ~1.9GB
                    'large-v1': 2900 * 1024 * 1024, # ~2.9GB
                    'large-v2': 2900 * 1024 * 1024, # ~2.9GB
                    'large-v3': 2900 * 1024 * 1024, # ~2.9GB
                    'large': 2900 * 1024 * 1024,    # ~2.9GB
                }
                estimated_size = model_sizes.get(self.model_name, 1000 * 1024 * 1024)  # é»˜è®¤1GB
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {estimated_size / (1024*1024):.1f} MB (æ ¹æ®æ¨¡å‹åç§°)")
                return estimated_size
        except Exception as e:
            logger.warning(f"æ¨¡å‹å¤§å°ä¼°ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            # é»˜è®¤è¿”å›1GB
            return 1024 * 1024 * 1024


class WhisperXPatcher(comfy.model_patcher.ModelPatcher):
    """WhisperXæ¨¡å‹ç®¡ç†å™¨ï¼Œé›†æˆComfyUIå†…å­˜ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, model, *args, **kwargs):
        super().__init__(model, *args, **kwargs)

    def patch_model(self, device_to=None, *args, **kwargs):
        """åŠ è½½æ¨¡å‹åˆ°ç›®æ ‡è®¾å¤‡"""
        target_device = self.load_device

        if self.model.whisperx_model is None:
            logger.info(f"Loading WhisperX model '{self.model.model_name}' to {target_device}...")
            self.model.load_model(target_device)
            self.size = self.model.model_loaded_weight_memory
        else:
            logger.info(f"WhisperX model '{self.model.model_name}' already loaded")

        return super().patch_model(device_to=target_device, *args, **kwargs)

    def unpatch_model(self, device_to=None, unpatch_weights=True, *args, **kwargs):
        """å¸è½½æ¨¡å‹é‡Šæ”¾æ˜¾å­˜"""
        if unpatch_weights:
            logger.info(f"Unloading WhisperX model '{self.model.model_name}'...")
            self.model.whisperx_model = None
            self.model.align_model = None
            self.model.model_loaded_weight_memory = 0
            mm.soft_empty_cache()
        
        return super().unpatch_model(device_to, unpatch_weights, *args, **kwargs)


class ApplyWhisperXAlignmentNode:
    """WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–æ”¯æŒçš„è¯­è¨€é€‰é¡¹
        language_options = [
            "auto",      # è‡ªåŠ¨æ£€æµ‹
            "Chinese",   # ä¸­æ–‡
            "English",   # è‹±è¯­  
            "Japanese",  # æ—¥è¯­
            "Korean",    # éŸ©è¯­
            "French",    # æ³•è¯­
            "German",    # å¾·è¯­
            "Spanish",   # è¥¿ç­ç‰™è¯­
            "Italian"    # æ„å¤§åˆ©è¯­
        ]
        
        # æ¨¡å‹å¤§å°é€‰é¡¹
        model_options = [
            'tiny', 'base', 'small', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large'
        ]
        
        return {
            "required": {
                "audio": ("AUDIO",),
                "reference_text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "è¾“å…¥å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬ã€‚WhisperXå°†æŠŠæ­¤æ–‡æœ¬ä¸­çš„æ¯ä¸ªè¯ç²¾ç¡®å¯¹é½åˆ°éŸ³é¢‘æ—¶é—´ç‚¹ã€‚\næ³¨æ„ï¼šè¿™æ˜¯çœŸæ­£çš„å¼ºåˆ¶å¯¹é½ï¼Œéœ€è¦æ–‡æœ¬ä¸éŸ³é¢‘å†…å®¹å®Œå…¨åŒ¹é…ï¼"
                }),
                "model": (model_options, {"default": "base"}),
            },
            "optional": {
                "language": (language_options, {"default": "auto"}),
                "return_char_alignments": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦è¿”å›å­—ç¬¦çº§åˆ«çš„å¯¹é½ä¿¡æ¯ï¼ˆéœ€è¦æ¨¡å‹æ”¯æŒï¼‰"
                }),
                "alignment_mode": (["forced_alignment", "asr_with_mapping"], {
                    "default": "forced_alignment",
                    "tooltip": "å¯¹é½æ¨¡å¼ï¼šå¼ºåˆ¶å¯¹é½ï¼ˆæ¨èï¼‰æˆ–ASRè½¬å½•åæ˜ å°„ï¼ˆå¤‡ç”¨ï¼‰"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "whisper_alignment", "whisper_alignment", "STRING")
    RETURN_NAMES = ("aligned_text", "segments_alignment", "words_alignment", "process_log")
    FUNCTION = "apply_whisperx_alignment"
    CATEGORY = "å­—å¹•"

    def apply_whisperx_alignment(self, 
                               audio: Dict[str, torch.Tensor],
                               reference_text: str,
                               model: str,
                               language: str = "auto",
                               return_char_alignments: bool = False,
                               alignment_mode: str = "forced_alignment") -> Tuple[str, List[Dict], List[Dict], str]:
        """
        æ‰§è¡ŒWhisperXçœŸæ­£çš„å¼ºåˆ¶å¯¹é½ï¼ˆForced Alignmentï¼‰
        
        å¼ºåˆ¶å¯¹é½æ˜¯æŒ‡ï¼šç»™å®šå‡†ç¡®çš„å‚è€ƒæ–‡æœ¬å’ŒéŸ³é¢‘ï¼Œå°†æ–‡æœ¬ä¸­çš„æ¯ä¸ªè¯/å¥ç²¾ç¡®åœ°
        å¯¹é½åˆ°éŸ³é¢‘çš„å…·ä½“æ—¶é—´æ®µã€‚è¿™è¦æ±‚å‚è€ƒæ–‡æœ¬ä¸éŸ³é¢‘å†…å®¹å®Œå…¨åŒ¹é…ã€‚
        
        Args:
            audio: éŸ³é¢‘å¼ é‡å­—å…¸ {"waveform": tensor, "sample_rate": int}
            reference_text: å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬ï¼ˆå¿…é¡»ä¸éŸ³é¢‘å†…å®¹åŒ¹é…ï¼‰
            model: WhisperXæ¨¡å‹å¤§å°
            language: è¯­è¨€ï¼ˆautoä¸ºè‡ªåŠ¨æ£€æµ‹ï¼‰
            return_char_alignments: æ˜¯å¦è¿”å›å­—ç¬¦çº§å¯¹é½
            alignment_mode: å¯¹é½æ¨¡å¼ï¼ˆå¼ºåˆ¶å¯¹é½æˆ–ASR+æ˜ å°„ï¼‰
            
        Returns:
            (å¯¹é½åæ–‡æœ¬, å¥çº§å¯¹é½æ•°æ®, è¯çº§å¯¹é½æ•°æ®, å¤„ç†æ—¥å¿—)
        """
        log_messages = []
        
        try:
            # æ˜¾ç¤ºå¯¹é½æ¨¡å¼
            mode_display = "å¼ºåˆ¶å¯¹é½" if alignment_mode == "forced_alignment" else "ASR+æ˜ å°„å¯¹é½"
            log_messages.append(f"ğŸ¯ å¯¹é½æ¨¡å¼: {mode_display}")
            
            if alignment_mode == "forced_alignment":
                log_messages.append("ğŸ’¡ å¼ºåˆ¶å¯¹é½ï¼šå°†å‚è€ƒæ–‡æœ¬ä¸­çš„æ¯ä¸ªè¯ç²¾ç¡®å¯¹é½åˆ°éŸ³é¢‘æ—¶é—´ç‚¹")
                log_messages.append("âš ï¸ æ³¨æ„ï¼šå‚è€ƒæ–‡æœ¬å¿…é¡»ä¸éŸ³é¢‘å†…å®¹å®Œå…¨åŒ¹é…æ‰èƒ½è·å¾—æœ€ä½³æ•ˆæœ")
            else:
                log_messages.append("ğŸ’¡ ASR+æ˜ å°„ï¼šå…ˆè¿›è¡Œè¯­éŸ³è¯†åˆ«ï¼Œå†å°†ç»“æœæ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬")
            
            # éªŒè¯è¾“å…¥
            if not reference_text.strip():
                error_msg = "è¯·æä¾›å‡†ç¡®çš„å‚è€ƒæ–‡æœ¬ç”¨äºå¯¹é½"
                log_messages.append(f"âŒ {error_msg}")
                return "", [], [], "\n".join(log_messages)
            
            log_messages.append(f"ğŸ“ å‚è€ƒæ–‡æœ¬é•¿åº¦: {len(reference_text)} å­—ç¬¦")
            log_messages.append(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
            log_messages.append(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = folder_paths.get_temp_directory()
            os.makedirs(temp_dir, exist_ok=True)
            audio_save_path = os.path.join(temp_dir, f"whisperx_{uuid.uuid1()}.wav")
            
            torchaudio.save(
                audio_save_path, 
                audio['waveform'].squeeze(0), 
                audio["sample_rate"]
            )
            log_messages.append(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {os.path.basename(audio_save_path)}")
            
            # è·å–æˆ–åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
            language_code = self._get_language_code(language)
            cache_key = f"{model}_{language_code}"
            
            if cache_key not in WHISPERX_PATCHER_CACHE:
                load_device = mm.get_torch_device()
                log_messages.append(f"ğŸ”„ åˆå§‹åŒ–WhisperXæ¨¡å‹ç®¡ç†å™¨: {model}")
                
                model_wrapper = WhisperXModelWrapper(model, language_code)
                patcher = WhisperXPatcher(
                    model=model_wrapper,
                    load_device=load_device,
                    offload_device=mm.unet_offload_device(),
                    size=0  # å°†åœ¨æ¨¡å‹åŠ è½½æ—¶è®¾ç½®
                )
                WHISPERX_PATCHER_CACHE[cache_key] = patcher
            
            patcher = WHISPERX_PATCHER_CACHE[cache_key]
            
            # åŠ è½½æ¨¡å‹
            mm.load_model_gpu(patcher)
            whisperx_model = patcher.model.whisperx_model
            
            if whisperx_model is None:
                error_msg = f"WhisperXæ¨¡å‹åŠ è½½å¤±è´¥: {model}"
                log_messages.append(f"âŒ {error_msg}")
                raise RuntimeError(error_msg)
            
            log_messages.append("âœ… WhisperXæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # çœŸæ­£çš„å¼ºåˆ¶å¯¹é½ï¼šä½¿ç”¨å‚è€ƒæ–‡æœ¬ä¸éŸ³é¢‘è¿›è¡Œå¯¹é½
            log_messages.append("ğŸ¯ å¼€å§‹çœŸæ­£çš„å¼ºåˆ¶å¯¹é½...")
            log_messages.append(f"ğŸ“ å‚è€ƒæ–‡æœ¬: {reference_text[:100]}{'...' if len(reference_text) > 100 else ''}")
            
            # æ£€æµ‹è¯­è¨€ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
            if not language_code or language_code == "auto":
                log_messages.append("ğŸ” è‡ªåŠ¨æ£€æµ‹éŸ³é¢‘è¯­è¨€...")
                temp_result = whisperx_model.transcribe(audio_save_path, batch_size=16)
                detected_language = temp_result.get("language", "en")
                log_messages.append(f"ğŸ” æ£€æµ‹åˆ°è¯­è¨€: {detected_language}")
            else:
                detected_language = language_code
                log_messages.append(f"ğŸŒ ä½¿ç”¨æŒ‡å®šè¯­è¨€: {detected_language}")
            
            # åŠ è½½å¯¹é½æ¨¡å‹
            log_messages.append("ğŸ¯ åŠ è½½å¼ºåˆ¶å¯¹é½æ¨¡å‹...")
            try:
                align_device = convert_device_for_whisperx(patcher.load_device)
                model_a, metadata = whisperx.load_align_model(
                    language_code=detected_language,
                    device=align_device
                )
                patcher.model.align_model = model_a
                log_messages.append("âœ… å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                error_msg = f"âŒ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥: {e}"
                log_messages.append(error_msg)
                log_messages.append("ğŸ’¡ å¼ºåˆ¶å¯¹é½éœ€è¦å¯¹é½æ¨¡å‹æ”¯æŒï¼Œè¯·æ£€æŸ¥è¯­è¨€æ˜¯å¦å—æ”¯æŒ")
                return "", [], [], "\n".join(log_messages)
            
            # é¢„å¤„ç†å‚è€ƒæ–‡æœ¬ï¼šåˆ†å‰²æˆå¥å­
            log_messages.append("âœ‚ï¸ é¢„å¤„ç†å‚è€ƒæ–‡æœ¬...")
            reference_segments = self._prepare_reference_text(reference_text, detected_language)
            log_messages.append(f"ğŸ“„ å‚è€ƒæ–‡æœ¬åˆ†ä¸º {len(reference_segments)} ä¸ªå¥å­")
            
            # æ ¹æ®å¯¹é½æ¨¡å¼é€‰æ‹©æ‰§è¡Œè·¯å¾„
            if alignment_mode == "forced_alignment":
                log_messages.append("âš¡ æ‰§è¡ŒçœŸæ­£çš„å¼ºåˆ¶å¯¹é½...")
                try:
                    # æ„é€ ç”¨äºå¯¹é½çš„segmentsç»“æ„ï¼Œä½¿ç”¨å‚è€ƒæ–‡æœ¬
                    mock_segments = []
                    for i, ref_text in enumerate(reference_segments):
                        mock_segments.append({
                            "start": 0.0,  # ä¸´æ—¶æ—¶é—´ï¼Œä¼šè¢«å¯¹é½è¦†ç›–
                            "end": 0.0,    # ä¸´æ—¶æ—¶é—´ï¼Œä¼šè¢«å¯¹é½è¦†ç›–
                            "text": ref_text.strip()
                        })
                    
                    # ä½¿ç”¨WhisperXçš„alignå‡½æ•°è¿›è¡Œå¼ºåˆ¶å¯¹é½
                    aligned_result = whisperx.align(
                        mock_segments,
                        model_a,
                        metadata,
                        audio_save_path,
                        align_device,
                        return_char_alignments=return_char_alignments
                    )
                    
                    segments = aligned_result["segments"]
                    words = aligned_result.get("word_segments", [])
                    
                    log_messages.append(f"âœ… å¼ºåˆ¶å¯¹é½å®Œæˆ: {len(segments)} å¥, {len(words)} è¯")
                    
                except Exception as align_error:
                    log_messages.append(f"âŒ å¼ºåˆ¶å¯¹é½å¤±è´¥: {align_error}")
                    log_messages.append("ğŸ”„ è‡ªåŠ¨é™çº§ä¸ºASR+æ˜ å°„æ¨¡å¼...")
                    alignment_mode = "asr_with_mapping"  # è‡ªåŠ¨åˆ‡æ¢æ¨¡å¼
            
            # ASR+æ˜ å°„æ¨¡å¼ï¼ˆæˆ–å¼ºåˆ¶å¯¹é½å¤±è´¥åçš„é™çº§ï¼‰
            if alignment_mode == "asr_with_mapping":
                log_messages.append("ğŸ™ï¸ æ‰§è¡ŒASRè½¬å½•+æ–‡æœ¬æ˜ å°„...")
                
                # å…ˆè¿›è¡ŒASRè½¬å½•
                transcribe_result = whisperx_model.transcribe(
                    audio_save_path,
                    batch_size=16,
                    language=detected_language if detected_language != "auto" else None
                )
                
                log_messages.append(f"ğŸ™ï¸ ASRè½¬å½•å®Œæˆ: {len(transcribe_result['segments'])} ä¸ªç‰‡æ®µ")
                
                # ä½¿ç”¨è½¬å½•ç»“æœè¿›è¡Œå¯¹é½
                aligned_result = whisperx.align(
                    transcribe_result["segments"],
                    model_a,
                    metadata,
                    audio_save_path,
                    align_device,
                    return_char_alignments=return_char_alignments
                )
                
                segments = aligned_result["segments"] 
                words = aligned_result.get("word_segments", [])
                
                log_messages.append(f"ğŸ”— ASRå¯¹é½å®Œæˆ: {len(segments)} å¥, {len(words)} è¯")
                
                # å°è¯•å°†ASRç»“æœæ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬
                segments, words = self._map_to_reference_text(segments, words, reference_text, log_messages)
            
            log_messages.append(f"ğŸ‰ å¯¹é½å®Œæˆ! å¥å­: {len(segments)}, è¯è¯­: {len(words)}")
            
            # æ ¼å¼åŒ–è¾“å‡ºä¸ºwhisper_alignmentæ ¼å¼
            segments_alignment = []
            words_alignment = []
            aligned_text_parts = []
            
            for segment in segments:
                # å¥çº§åˆ«å¯¹é½
                segment_data = {
                    "start": segment.get("start", 0.0),
                    "end": segment.get("end", 0.0),
                    "value": segment.get("text", "").strip(),
                    "confidence": segment.get("confidence", 1.0)
                }
                segments_alignment.append(segment_data)
                aligned_text_parts.append(segment_data["value"])
                
                # è¯çº§åˆ«å¯¹é½
                if "words" in segment:
                    for word in segment["words"]:
                        word_data = {
                            "start": word.get("start", segment_data["start"]),
                            "end": word.get("end", segment_data["end"]),
                            "value": word.get("word", "").strip(),
                            "confidence": word.get("confidence", 1.0)
                        }
                        words_alignment.append(word_data)
            
            # ç”Ÿæˆå¯¹é½åçš„å®Œæ•´æ–‡æœ¬
            aligned_text = " ".join(aligned_text_parts)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(audio_save_path)
                log_messages.append("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                log_messages.append(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
            
            log_messages.append(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            log_messages.append(f"  - å¯¹é½å¥å­æ•°: {len(segments_alignment)}")
            log_messages.append(f"  - å¯¹é½è¯è¯­æ•°: {len(words_alignment)}")
            log_messages.append(f"  - æ£€æµ‹è¯­è¨€: {detected_language}")
            log_messages.append(f"  - æ–‡æœ¬åŒ¹é…åº¦: {self._calculate_text_similarity(reference_text, aligned_text):.1%}")
            
            return aligned_text, segments_alignment, words_alignment, "\n".join(log_messages)
            
        except Exception as e:
            error_msg = f"WhisperXå¯¹é½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            import traceback
            logger.error(traceback.format_exc())
            
            # æä¾›å…·ä½“çš„é”™è¯¯åˆ†æå’Œè§£å†³å»ºè®®
            error_analysis = self._analyze_error(str(e))
            log_messages.append(f"âŒ {error_msg}")
            if error_analysis:
                log_messages.extend(error_analysis)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'audio_save_path' in locals():
                    os.remove(audio_save_path)
            except:
                pass
            
            return "", [], [], "\n".join(log_messages)
    
    def _get_language_code(self, language: str) -> str:
        """å°†è¯­è¨€åç§°è½¬æ¢ä¸ºä»£ç """
        language_mapping = {
            "auto": None,
            "chinese": "zh",
            "english": "en", 
            "japanese": "ja",
            "korean": "ko",
            "french": "fr",
            "german": "de", 
            "spanish": "es",
            "italian": "it"
        }
        return language_mapping.get(language.lower(), None)
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„è¯è¯­é‡å ç‡è®¡ç®—
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _prepare_reference_text(self, reference_text: str, language: str) -> List[str]:
        """é¢„å¤„ç†å‚è€ƒæ–‡æœ¬ï¼Œåˆ†å‰²æˆé€‚åˆå¯¹é½çš„å¥å­ç‰‡æ®µ"""
        import re
        
        # æ¸…ç†æ–‡æœ¬
        text = reference_text.strip()
        if not text:
            return []
        
        # æ ¹æ®è¯­è¨€ä½¿ç”¨ä¸åŒçš„åˆ†å¥ç­–ç•¥
        if language in ['zh', 'ja', 'ko']:  # ä¸­æ—¥éŸ©è¯­è¨€
            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›\.\!\?;]', text)
        else:  # å…¶ä»–è¯­è¨€
            # æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å¥
            sentences = re.split(r'[\.!\?]+', text)
        
        # æ¸…ç†å¹¶è¿‡æ»¤ç©ºå¥å­
        processed_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence:
                # å¯¹äºè¿‡é•¿çš„å¥å­ï¼Œè¿›ä¸€æ­¥åˆ†å‰²
                if len(sentence) > 200:  # å­—ç¬¦æ•°é˜ˆå€¼
                    # æŒ‰é€—å·æˆ–å…¶ä»–æ ‡ç‚¹è¿›ä¸€æ­¥åˆ†å‰²
                    sub_sentences = re.split(r'[,ï¼Œã€]', sentence)
                    for sub in sub_sentences:
                        sub = sub.strip()
                        if sub:
                            processed_sentences.append(sub)
                else:
                    processed_sentences.append(sentence)
        
        return processed_sentences if processed_sentences else [text]
    
    def _map_to_reference_text(self, segments: List[Dict], words: List[Dict], reference_text: str, log_messages: List[str]) -> Tuple[List[Dict], List[Dict]]:
        """å°†ASRè½¬å½•ç»“æœæ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬ï¼ˆé™çº§æ–¹æ¡ˆï¼‰"""
        log_messages.append("ğŸ”„ å°è¯•å°†ASRç»“æœæ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬...")
        
        # æå–ASRè½¬å½•çš„æ–‡æœ¬
        asr_text = " ".join([seg.get("text", "") for seg in segments])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = self._calculate_text_similarity(reference_text, asr_text)
        log_messages.append(f"ğŸ“Š ASRä¸å‚è€ƒæ–‡æœ¬ç›¸ä¼¼åº¦: {similarity:.1%}")
        
        if similarity > 0.7:  # ç›¸ä¼¼åº¦é˜ˆå€¼
            log_messages.append("âœ… ç›¸ä¼¼åº¦è¾ƒé«˜ï¼Œç›´æ¥ä½¿ç”¨ASRå¯¹é½ç»“æœ")
            return segments, words
        else:
            log_messages.append("âš ï¸ ç›¸ä¼¼åº¦è¾ƒä½ï¼Œå°è¯•æ–‡æœ¬å¯¹é½...")
            
            # ç®€å•çš„æ–‡æœ¬å¯¹é½ç­–ç•¥ï¼šæŒ‰æ—¶é—´æ¯”ä¾‹åˆ†é…
            reference_segments = self._prepare_reference_text(reference_text, "en")
            total_duration = max([seg.get("end", 0) for seg in segments]) if segments else 0.0
            
            aligned_segments = []
            for i, ref_text in enumerate(reference_segments):
                start_time = (i / len(reference_segments)) * total_duration
                end_time = ((i + 1) / len(reference_segments)) * total_duration
                
                aligned_segments.append({
                    "start": start_time,
                    "end": end_time,
                    "text": ref_text,
                    "confidence": 0.5  # æ ‡è®°ä¸ºä½ç½®ä¿¡åº¦
                })
            
            # ä¸ºmapped segmentsç”Ÿæˆç®€å•çš„word alignment
            mapped_words = []
            for seg in aligned_segments:
                seg_duration = seg["end"] - seg["start"]
                seg_words = seg["text"].split()
                if seg_words:
                    word_duration = seg_duration / len(seg_words)
                    for j, word in enumerate(seg_words):
                        word_start = seg["start"] + j * word_duration
                        word_end = word_start + word_duration
                        mapped_words.append({
                            "start": word_start,
                            "end": word_end,
                            "word": word,
                            "confidence": 0.5
                        })
            
            log_messages.append(f"ğŸ“ æ˜ å°„å®Œæˆ: {len(aligned_segments)} å¥, {len(mapped_words)} è¯")
            return aligned_segments, mapped_words
    
    def _analyze_error(self, error_str: str) -> List[str]:
        """åˆ†æé”™è¯¯å¹¶æä¾›è§£å†³å»ºè®®"""
        suggestions = []
        
        if "incompatible constructor arguments" in error_str and "ctranslate2" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°CTranslate2ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ›´æ–°WhisperX: pip install --upgrade whisperx",
                "   2. æˆ–é™çº§CTranslate2: pip install ctranslate2==3.24.0", 
                "   3. æˆ–ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬: pip install whisperx==3.1.1",
                "   4. æ£€æŸ¥CUDAç‰ˆæœ¬å…¼å®¹æ€§"
            ])
        
        elif "unsupported device" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡æ ¼å¼ä¸å…¼å®¹é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. å·²è‡ªåŠ¨ä¿®å¤è®¾å¤‡æ ¼å¼è½¬æ¢",
                "   2. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•é‡å¯ComfyUI",
                "   3. æ£€æŸ¥CUDAé©±åŠ¨æ˜¯å¦æ­£å¸¸å·¥ä½œ",
                "   4. å°è¯•ä½¿ç”¨CPUæ¨¡å¼æµ‹è¯•"
            ])
        
        elif "has no attribute 'parameters'" in error_str or "has no attribute" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹ç»“æ„å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. âœ… å·²è‡ªåŠ¨ä¿®å¤æ¨¡å‹å¤§å°ä¼°ç®—æ–¹æ³•",
                "   2. å°è¯•é‡å¯ComfyUIé‡æ–°åŠ è½½ä¿®å¤åçš„ä»£ç ",
                "   3. å¦‚æœé—®é¢˜æŒç»­ï¼Œæ£€æŸ¥WhisperXç‰ˆæœ¬å…¼å®¹æ€§",
                "   4. è€ƒè™‘é™çº§åˆ°å…¼å®¹ç‰ˆæœ¬: pip install whisperx==3.1.1"
            ])
        
        elif "device" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡ç›¸å…³é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥CUDAæ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. å°è¯•ä½¿ç”¨CPUæ¨¡å¼",
                "   3. é‡å¯ComfyUIé‡æ–°åˆå§‹åŒ–è®¾å¤‡"
            ])
        
        elif "memory" in error_str.lower() or "oom" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°å†…å­˜ä¸è¶³ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (å¦‚ baseã€small)",
                "   2. é™ä½batch_size",
                "   3. å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„ç¨‹åº"
            ])
        
        elif "model" in error_str.lower() and "load" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹åŠ è½½é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "   2. æ¸…ç†æ¨¡å‹ç¼“å­˜ç›®å½•",
                "   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶"
            ])
        
        else:
            suggestions.extend([
                "ğŸ”§ é€šç”¨è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. é‡å¯ComfyUI",
                "   3. æŸ¥çœ‹å®Œæ•´é”™è¯¯æ—¥å¿—",
                "   4. å°è¯•ä½¿ç”¨è¾ƒå°çš„éŸ³é¢‘æ–‡ä»¶æµ‹è¯•"
            ])
        
        return suggestions


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": ApplyWhisperXAlignmentNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": "ğŸ¯ WhisperX å¼ºåˆ¶å¯¹é½ (Forced Alignment)"
}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸµ WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹æµ‹è¯•")
    node = ApplyWhisperXAlignmentNode()
    print("ğŸ“‹ è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
    print("ğŸ¯ è¿”å›ç±»å‹:", node.RETURN_TYPES)
    print("ğŸ“ è¿”å›åç§°:", node.RETURN_NAMES)