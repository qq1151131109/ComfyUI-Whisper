"""
ComfyUI WhisperX å¼ºåˆ¶å¯¹é½èŠ‚ç‚¹
ä¸ç°æœ‰ apply_whisper èŠ‚ç‚¹æ¥å£ä¿æŒä¸€è‡´ï¼Œæ”¯æŒéŸ³é¢‘æµè¾“å…¥
ç”¨äºå°†å‡†ç¡®æ–‡æœ¬ä¸éŸ³é¢‘è¿›è¡Œç²¾ç¡®æ—¶é—´åŒæ­¥ï¼Œç”Ÿæˆé«˜è´¨é‡å­—å¹•
"""

import os
import sys
import json
import uuid
import tempfile
import torchaudio
import torch
import logging
import folder_paths
from typing import Dict, Any, Tuple, Optional, List

import comfy.model_management as mm
import comfy.model_patcher

logger = logging.getLogger(__name__)

# WhisperXä¾èµ–æ£€æŸ¥å’Œç‰ˆæœ¬å…¼å®¹æ€§éªŒè¯
try:
    import whisperx
    WHISPERX_AVAILABLE = True
    whisperx_version = getattr(whisperx, '__version__', 'Unknown')
    logger.info(f"WhisperXç‰ˆæœ¬: {whisperx_version}")
except ImportError as e:
    WHISPERX_AVAILABLE = False
    whisperx = None
    logger.warning(f"WhisperXæœªå®‰è£…: {e}")

try:
    import ctranslate2
    ctranslate2_version = getattr(ctranslate2, '__version__', 'Unknown')
    logger.info(f"CTranslate2ç‰ˆæœ¬: {ctranslate2_version}")
    
    # ç‰ˆæœ¬å…¼å®¹æ€§æ£€æŸ¥
    if ctranslate2_version != 'Unknown':
        major_version = int(ctranslate2_version.split('.')[0])
        if major_version >= 4:
            logger.warning("âš ï¸ CTranslate2ç‰ˆæœ¬è¾ƒæ–°ï¼Œå¯èƒ½ä¸WhisperXä¸å…¼å®¹ã€‚æ¨èä½¿ç”¨3.24.0ç‰ˆæœ¬")
except ImportError:
    logger.warning("CTranslate2æœªå®‰è£…ï¼Œå¯èƒ½å¯¼è‡´WhisperXåŠŸèƒ½å¼‚å¸¸")

try:
    import pyannote.audio
    pyannote_version = getattr(pyannote.audio, '__version__', 'Unknown')
    logger.info(f"Pyannote.audioç‰ˆæœ¬: {pyannote_version}")
    
    # ç‰ˆæœ¬å…¼å®¹æ€§è­¦å‘Š
    if pyannote_version != 'Unknown':
        major_version = int(pyannote_version.split('.')[0])
        if major_version >= 3:
            logger.warning("âš ï¸ Pyannote.audioç‰ˆæœ¬(3.x)ä¸WhisperXè®­ç»ƒç‰ˆæœ¬(0.x)å­˜åœ¨å·¨å¤§å·®å¼‚ï¼Œå¯èƒ½å½±å“VADè´¨é‡")
            logger.info("ğŸ’¡ å»ºè®®: è€ƒè™‘ç¦ç”¨VADæˆ–é™çº§åˆ°å…¼å®¹ç‰ˆæœ¬")
except ImportError:
    logger.info("Pyannote.audioæœªå®‰è£…ï¼Œå°†ä¸æ”¯æŒé«˜çº§VADåŠŸèƒ½")

WHISPERX_MODEL_SUBDIR = os.path.join("stt", "whisperx")
WHISPERX_PATCHER_CACHE = {}


def convert_device_for_whisperx(device):
    """å°†torchè®¾å¤‡æ ¼å¼è½¬æ¢ä¸ºWhisperXå…¼å®¹çš„è®¾å¤‡å­—ç¬¦ä¸²ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if hasattr(device, 'type'):
        device_type = device.type
    else:
        device_str = str(device).lower()
        if 'cuda' in device_str:
            device_type = 'cuda'
        elif 'cpu' in device_str:
            device_type = 'cpu'
        else:
            device_type = 'cpu'  # é»˜è®¤ä½¿ç”¨CPU
    
    # WhisperXåªæ”¯æŒ 'cuda' æˆ– 'cpu'ï¼Œä¸æ”¯æŒ 'cuda:0' æ ¼å¼
    if device_type == 'cuda':
        return 'cuda'
    else:
        return 'cpu'


def validate_device_compatibility(device_str: str) -> bool:
    """éªŒè¯è®¾å¤‡å…¼å®¹æ€§ï¼ˆå…¨å±€å‡½æ•°ï¼‰"""
    if device_str not in ['cuda', 'cpu']:
        logger.warning(f"è®¾å¤‡ '{device_str}' å¯èƒ½ä¸è¢«WhisperXæ”¯æŒï¼Œå·²è½¬æ¢ä¸ºå…¼å®¹æ ¼å¼")
        return False
    
    if device_str == 'cuda' and torch and not torch.cuda.is_available():
        logger.warning("CUDAè®¾å¤‡ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False
    
    return True


class WhisperXModelWrapper(torch.nn.Module):
    """WhisperXæ¨¡å‹åŒ…è£…å™¨ï¼Œé›†æˆComfyUIæ¨¡å‹ç®¡ç†"""
    
    def __init__(self, model_name, language=None):
        super().__init__()
        self.model_name = model_name
        self.language = language
        self.whisperx_model = None
        self.align_model = None
        self.model_loaded_weight_memory = 0
        self.device = mm.get_torch_device()
        self.compute_type = "float16" if self.device.type == "cuda" else "int8"

    def load_model(self, device):
        """åŠ è½½WhisperXæ¨¡å‹åˆ°æŒ‡å®šè®¾å¤‡"""
        if not WHISPERX_AVAILABLE:
            raise ImportError("WhisperX not installed. Please run: pip install whisperx")
        
        try:
            # è½¬æ¢è®¾å¤‡æ ¼å¼ï¼štorch.device -> WhisperXå…¼å®¹æ ¼å¼
            device_str = convert_device_for_whisperx(device)
            
            # éªŒè¯è®¾å¤‡å…¼å®¹æ€§
            if not validate_device_compatibility(device_str):
                if device_str == 'cuda':
                    device_str = 'cpu'  # å›é€€åˆ°CPU
                    logger.info("CUDAä¸å¯ç”¨ï¼Œå›é€€åˆ°CPUæ¨¡å¼")
            
            logger.info(f"Loading WhisperX model with device: {device_str}")
            
            # åŠ è½½Whisper ASRæ¨¡å‹
            self.whisperx_model = whisperx.load_model(
                self.model_name,
                device_str,  # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼çš„è®¾å¤‡
                compute_type=self.compute_type,
                language=self.language if self.language != "auto" else None
            )
            
            # ä¼°ç®—æ¨¡å‹å¤§å°ç”¨äºå†…å­˜ç®¡ç†
            self.model_loaded_weight_memory = self._estimate_model_size()
            
            logger.info(f"WhisperX model '{self.model_name}' loaded successfully")
            return True
            
        except Exception as e:
            logger.error(f"Failed to load WhisperX model: {e}")
            raise
    
    def _estimate_model_size(self):
        """å®‰å…¨ä¼°ç®—WhisperXæ¨¡å‹å¤§å°"""
        try:
            # å°è¯•å¤šç§æ–¹æ³•ä¼°ç®—æ¨¡å‹å¤§å°
            if hasattr(self.whisperx_model, 'model') and hasattr(self.whisperx_model.model, 'parameters'):
                # æ ‡å‡†PyTorchæ¨¡å‹
                size = sum(p.numel() * p.element_size() for p in self.whisperx_model.model.parameters())
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {size / (1024*1024):.1f} MB (é€šè¿‡parameters)")
                return size
            elif hasattr(self.whisperx_model, 'model') and hasattr(self.whisperx_model.model, 'get_memory_stats'):
                # CTranslate2æ¨¡å‹
                stats = self.whisperx_model.model.get_memory_stats()
                size = stats.get('model_size', 0)
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {size / (1024*1024):.1f} MB (é€šè¿‡memory_stats)")
                return size
            else:
                # æ ¹æ®æ¨¡å‹åç§°ä¼°ç®—å¤§å°ï¼ˆå­—èŠ‚ï¼‰
                model_sizes = {
                    'tiny': 150 * 1024 * 1024,      # ~150MB
                    'base': 280 * 1024 * 1024,      # ~280MB  
                    'small': 970 * 1024 * 1024,     # ~970MB
                    'medium': 1940 * 1024 * 1024,   # ~1.9GB
                    'large-v1': 2900 * 1024 * 1024, # ~2.9GB
                    'large-v2': 2900 * 1024 * 1024, # ~2.9GB
                    'large-v3': 2900 * 1024 * 1024, # ~2.9GB
                    'large': 2900 * 1024 * 1024,    # ~2.9GB
                }
                estimated_size = model_sizes.get(self.model_name, 1000 * 1024 * 1024)  # é»˜è®¤1GB
                logger.info(f"æ¨¡å‹å¤§å°ä¼°ç®—: {estimated_size / (1024*1024):.1f} MB (æ ¹æ®æ¨¡å‹åç§°)")
                return estimated_size
        except Exception as e:
            logger.warning(f"æ¨¡å‹å¤§å°ä¼°ç®—å¤±è´¥: {e}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
            # é»˜è®¤è¿”å›1GB
            return 1024 * 1024 * 1024


class WhisperXPatcher(comfy.model_patcher.ModelPatcher):
    """WhisperXæ¨¡å‹ç®¡ç†å™¨ï¼Œé›†æˆComfyUIå†…å­˜ç®¡ç†ç³»ç»Ÿ"""
    
    def __init__(self, model, *args, **kwargs):
        super().__init__(model, *args, **kwargs)

    def patch_model(self, device_to=None, *args, **kwargs):
        """åŠ è½½æ¨¡å‹åˆ°ç›®æ ‡è®¾å¤‡"""
        target_device = self.load_device

        if self.model.whisperx_model is None:
            logger.info(f"Loading WhisperX model '{self.model.model_name}' to {target_device}...")
            self.model.load_model(target_device)
            self.size = self.model.model_loaded_weight_memory
        else:
            logger.info(f"WhisperX model '{self.model.model_name}' already loaded")

        return super().patch_model(device_to=target_device, *args, **kwargs)

    def unpatch_model(self, device_to=None, unpatch_weights=True, *args, **kwargs):
        """å¸è½½æ¨¡å‹é‡Šæ”¾æ˜¾å­˜"""
        if unpatch_weights:
            logger.info(f"Unloading WhisperX model '{self.model.model_name}'...")
            self.model.whisperx_model = None
            self.model.align_model = None
            self.model.model_loaded_weight_memory = 0
            mm.soft_empty_cache()
        
        return super().unpatch_model(device_to, unpatch_weights, *args, **kwargs)


class ApplyWhisperXAlignmentNode:
    """WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹"""
    
    @classmethod
    def INPUT_TYPES(cls):
        # è·å–æ”¯æŒçš„è¯­è¨€é€‰é¡¹
        language_options = [
            "auto",      # è‡ªåŠ¨æ£€æµ‹
            "Chinese",   # ä¸­æ–‡
            "English",   # è‹±è¯­  
            "Japanese",  # æ—¥è¯­
            "Korean",    # éŸ©è¯­
            "French",    # æ³•è¯­
            "German",    # å¾·è¯­
            "Spanish",   # è¥¿ç­ç‰™è¯­
            "Italian"    # æ„å¤§åˆ©è¯­
        ]
        
        # æ¨¡å‹å¤§å°é€‰é¡¹
        model_options = [
            'tiny', 'base', 'small', 'medium', 'large-v1', 'large-v2', 'large-v3', 'large'
        ]
        
        return {
            "required": {
                "audio": ("AUDIO",),
                "reference_text": ("STRING", {
                    "multiline": True,
                    "default": "",
                    "placeholder": "å¯é€‰ï¼šè¾“å…¥å‚è€ƒæ–‡æœ¬ç”¨äºå†…å®¹æ›¿æ¢ã€‚\nå¦‚æœç•™ç©ºï¼Œå°†ç›´æ¥ä½¿ç”¨ASRè½¬å½•ç»“æœã€‚\nå¦‚æœæä¾›ï¼Œå°†ä½¿ç”¨ASRçš„æ—¶é—´æˆ³ä½†æ˜¾ç¤ºæ‚¨çš„å‚è€ƒæ–‡æœ¬å†…å®¹ã€‚"
                }),
                "model": (model_options, {"default": "base"}),
            },
            "optional": {
                "language": (language_options, {"default": "auto"}),
                "return_char_alignments": ("BOOLEAN", {
                    "default": False,
                    "tooltip": "æ˜¯å¦è¿”å›å­—ç¬¦çº§åˆ«çš„å¯¹é½ä¿¡æ¯ï¼ˆéœ€è¦æ¨¡å‹æ”¯æŒï¼‰"
                }),
            }
        }

    RETURN_TYPES = ("STRING", "whisper_alignment", "whisper_alignment", "STRING")
    RETURN_NAMES = ("aligned_text", "segments_alignment", "words_alignment", "process_log")
    FUNCTION = "apply_whisperx_alignment"
    CATEGORY = "å­—å¹•"

    def apply_whisperx_alignment(self, 
                               audio: Dict[str, torch.Tensor],
                               reference_text: str,
                               model: str,
                               language: str = "auto",
                               return_char_alignments: bool = False) -> Tuple[str, List[Dict], List[Dict], str]:
        """
        æ‰§è¡ŒWhisperXéŸ³é¢‘è½¬å½•å’Œæ™ºèƒ½æ–‡æœ¬å¯¹é½
        
        æœ€ä½³å®è·µæµç¨‹ï¼š
        1. ASRè½¬å½•è·å¾—å‡†ç¡®çš„æ—¶é—´æˆ³
        2. å°è¯•WhisperXå¯¹é½ä¼˜åŒ–ï¼ˆå¤±è´¥åˆ™å›é€€ï¼‰
        3. æ™ºèƒ½æ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬ï¼ˆå¦‚æœæä¾›ï¼‰
        4. è‡ªåŠ¨æ–‡æœ¬æ¸…æ´—å’Œé”™è¯¯æ¢å¤
        
        Args:
            audio: éŸ³é¢‘å¼ é‡å­—å…¸ {"waveform": tensor, "sample_rate": int}
            reference_text: å‚è€ƒæ–‡æœ¬ï¼ˆç”¨äºæ›¿æ¢ASRè¯†åˆ«çš„å†…å®¹ï¼Œå¯é€‰ï¼‰
            model: WhisperXæ¨¡å‹å¤§å°
            language: è¯­è¨€ï¼ˆautoä¸ºè‡ªåŠ¨æ£€æµ‹ï¼‰
            return_char_alignments: æ˜¯å¦è¿”å›å­—ç¬¦çº§å¯¹é½
            
        Returns:
            (æœ€ç»ˆæ–‡æœ¬, å¥çº§å¯¹é½æ•°æ®, è¯çº§å¯¹é½æ•°æ®, å¤„ç†æ—¥å¿—)
        """
        log_messages = []
        
        try:
            log_messages.append("ğŸ¯ WhisperXæ™ºèƒ½å¯¹é½æ¨¡å¼ï¼šASRè½¬å½• + å¯¹é½ä¼˜åŒ– + æ–‡æœ¬æ˜ å°„")
            log_messages.append(f"ğŸ¤– ä½¿ç”¨æ¨¡å‹: {model}")
            log_messages.append(f"ğŸŒ è¯­è¨€è®¾ç½®: {language}")
            
            # å‚è€ƒæ–‡æœ¬æ˜¯å¯é€‰çš„
            if reference_text.strip():
                log_messages.append(f"ğŸ“ å‚è€ƒæ–‡æœ¬é•¿åº¦: {len(reference_text)} å­—ç¬¦ï¼ˆå°†ç”¨äºå†…å®¹æ›¿æ¢ï¼‰")
                # æ˜¾ç¤ºå‚è€ƒæ–‡æœ¬å‰100ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
                preview_text = reference_text.strip()[:100]
                log_messages.append(f"ğŸ“„ å‚è€ƒæ–‡æœ¬é¢„è§ˆ: {preview_text}{'...' if len(reference_text.strip()) > 100 else ''}")
            else:
                log_messages.append("ğŸ“ æœªæä¾›å‚è€ƒæ–‡æœ¬ï¼Œå°†ç›´æ¥ä½¿ç”¨ASRè½¬å½•ç»“æœ")
            
            # éŸ³é¢‘ä¿¡æ¯
            log_messages.append(f"ğŸµ éŸ³é¢‘ä¿¡æ¯: é‡‡æ ·ç‡={audio['sample_rate']}, å½¢çŠ¶={audio['waveform'].shape}")
            
            # é¢„å¤„ç†éŸ³é¢‘å¼ é‡ç¡®ä¿æ ¼å¼æ­£ç¡®
            waveform = audio['waveform']
            if len(waveform.shape) == 1:
                waveform = waveform.unsqueeze(0)  # æ·»åŠ channelç»´åº¦
            elif len(waveform.shape) == 3:
                waveform = waveform.squeeze(0)  # ç§»é™¤batchç»´åº¦
            
            # ç¡®ä¿æ˜¯å•å£°é“
            if waveform.shape[0] > 1:
                waveform = waveform.mean(dim=0, keepdim=True)  # è½¬æ¢ä¸ºå•å£°é“
            
            log_messages.append(f"ğŸ”§ é¢„å¤„ç†åéŸ³é¢‘å½¢çŠ¶: {waveform.shape}")
            
            # ä¿å­˜éŸ³é¢‘åˆ°ä¸´æ—¶æ–‡ä»¶
            temp_dir = folder_paths.get_temp_directory()
            os.makedirs(temp_dir, exist_ok=True)
            audio_save_path = os.path.join(temp_dir, f"whisperx_{uuid.uuid1()}.wav")
            
            try:
                torchaudio.save(
                    audio_save_path, 
                    waveform, 
                    audio["sample_rate"]
                )
                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„è¢«ä¿å­˜
                if os.path.exists(audio_save_path):
                    file_size = os.path.getsize(audio_save_path)
                    log_messages.append(f"ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜: {os.path.basename(audio_save_path)} ({file_size} bytes)")
                else:
                    raise RuntimeError("éŸ³é¢‘æ–‡ä»¶ä¿å­˜åä¸å­˜åœ¨")
                    
            except Exception as save_error:
                error_msg = f"éŸ³é¢‘æ–‡ä»¶ä¿å­˜å¤±è´¥: {save_error}"
                log_messages.append(f"âŒ {error_msg}")
                return "", [], [], "\n".join(log_messages)
            
            # è·å–æˆ–åˆ›å»ºæ¨¡å‹ç®¡ç†å™¨
            language_code = self._get_language_code(language)
            cache_key = f"{model}_{language_code}"
            
            if cache_key not in WHISPERX_PATCHER_CACHE:
                load_device = mm.get_torch_device()
                log_messages.append(f"ğŸ”„ åˆå§‹åŒ–WhisperXæ¨¡å‹ç®¡ç†å™¨: {model}")
                
                model_wrapper = WhisperXModelWrapper(model, language_code)
                patcher = WhisperXPatcher(
                    model=model_wrapper,
                    load_device=load_device,
                    offload_device=mm.unet_offload_device(),
                    size=0  # å°†åœ¨æ¨¡å‹åŠ è½½æ—¶è®¾ç½®
                )
                WHISPERX_PATCHER_CACHE[cache_key] = patcher
            
            patcher = WHISPERX_PATCHER_CACHE[cache_key]
            
            # åŠ è½½æ¨¡å‹
            mm.load_model_gpu(patcher)
            whisperx_model = patcher.model.whisperx_model
            
            if whisperx_model is None:
                error_msg = f"WhisperXæ¨¡å‹åŠ è½½å¤±è´¥: {model}"
                log_messages.append(f"âŒ {error_msg}")
                raise RuntimeError(error_msg)
            
            log_messages.append("âœ… WhisperXæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # çœŸæ­£çš„å¼ºåˆ¶å¯¹é½ï¼šä½¿ç”¨å‚è€ƒæ–‡æœ¬ä¸éŸ³é¢‘è¿›è¡Œå¯¹é½
            log_messages.append("ğŸ¯ å¼€å§‹çœŸæ­£çš„å¼ºåˆ¶å¯¹é½...")
            log_messages.append(f"ğŸ“ å‚è€ƒæ–‡æœ¬: {reference_text[:100]}{'...' if len(reference_text) > 100 else ''}")
            
            # æ£€æµ‹è¯­è¨€ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
            if not language_code or language_code == "auto":
                log_messages.append("ğŸ” è‡ªåŠ¨æ£€æµ‹éŸ³é¢‘è¯­è¨€...")
                temp_result = whisperx_model.transcribe(audio_save_path, batch_size=16)
                detected_language = temp_result.get("language", "en")
                log_messages.append(f"ğŸ” æ£€æµ‹åˆ°è¯­è¨€: {detected_language}")
            else:
                detected_language = language_code
                log_messages.append(f"ğŸŒ ä½¿ç”¨æŒ‡å®šè¯­è¨€: {detected_language}")
            
            # åŠ è½½å¯¹é½æ¨¡å‹
            log_messages.append("ğŸ¯ åŠ è½½å¼ºåˆ¶å¯¹é½æ¨¡å‹...")
            try:
                align_device = convert_device_for_whisperx(patcher.load_device)
                model_a, metadata = whisperx.load_align_model(
                    language_code=detected_language,
                    device=align_device
                )
                patcher.model.align_model = model_a
                log_messages.append("âœ… å¯¹é½æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e:
                error_msg = f"âŒ å¯¹é½æ¨¡å‹åŠ è½½å¤±è´¥: {e}"
                log_messages.append(error_msg)
                log_messages.append("ğŸ’¡ å¼ºåˆ¶å¯¹é½éœ€è¦å¯¹é½æ¨¡å‹æ”¯æŒï¼Œè¯·æ£€æŸ¥è¯­è¨€æ˜¯å¦å—æ”¯æŒ")
                return "", [], [], "\n".join(log_messages)
            
            # ç¬¬ä¸€æ­¥ï¼šASRè½¬å½•è·å¾—åŸºç¡€æ—¶é—´æˆ³
            log_messages.append("ğŸ™ï¸ ç¬¬ä¸€æ­¥ï¼šæ‰§è¡ŒASRè½¬å½•...")
            
            try:
                transcribe_result = whisperx_model.transcribe(
                    audio_save_path,
                    batch_size=16,
                    language=detected_language if detected_language != "auto" else None
                )
                
                if not transcribe_result or "segments" not in transcribe_result:
                    raise RuntimeError("ASRè½¬å½•è¿”å›ç©ºç»“æœæˆ–æ ¼å¼é”™è¯¯")
                
                segments_count = len(transcribe_result.get('segments', []))
                log_messages.append(f"âœ… ASRè½¬å½•å®Œæˆ: {segments_count} ä¸ªç‰‡æ®µ")
                
                if segments_count == 0:
                    log_messages.append("âš ï¸ ASRè½¬å½•æœªæ£€æµ‹åˆ°ä»»ä½•è¯­éŸ³ç‰‡æ®µ")
                    # è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
                    return "", [], [], "\n".join(log_messages)
                    
            except Exception as transcribe_error:
                error_msg = f"ASRè½¬å½•å¤±è´¥: {transcribe_error}"
                log_messages.append(f"âŒ {error_msg}")
                logger.error(error_msg)
                import traceback
                logger.error(traceback.format_exc())
                return "", [], [], "\n".join(log_messages)
            
            # ç¬¬äºŒæ­¥ï¼šå°è¯•WhisperXå¯¹é½ä¼˜åŒ–ï¼ˆè‡ªåŠ¨å®¹é”™ï¼‰
            log_messages.append("âš¡ ç¬¬äºŒæ­¥ï¼šå°è¯•WhisperXå¯¹é½ä¼˜åŒ–...")
            
            try:
                aligned_result = whisperx.align(
                    transcribe_result["segments"],
                    model_a,
                    metadata,
                    audio_save_path,
                    align_device,
                    return_char_alignments=return_char_alignments
                )
                
                segments = aligned_result["segments"]
                # ğŸš¨ å…³é”®ä¿®å¤ï¼šç¡®ä¿æ­£ç¡®æå–wordsæ•°æ®
                words = aligned_result.get("word_segments", [])
                
                # å¦‚æœword_segmentsä¸ºç©ºï¼Œä»segmentsä¸­æå–
                if not words:
                    log_messages.append("ğŸ”§ word_segmentsä¸ºç©ºï¼Œä»segmentsä¸­æå–words...")
                    for segment in segments:
                        if "words" in segment and segment["words"]:
                            words.extend(segment["words"])
                
                # å¼ºåˆ¶æ—¥å¿—æ˜¾ç¤º - ä½¿ç”¨loggerç¡®ä¿æ˜¾ç¤º
                debug_info = f"WhisperXå¯¹é½è°ƒè¯•: segments={len(segments)}, words={len(words)}"
                logger.info(debug_info)
                log_messages.append(f"ğŸ” {debug_info}")
                
                if words:
                    first_word = words[0]
                    logger.info(f"ç¬¬ä¸€ä¸ªè¯ç¤ºä¾‹: {first_word}")
                    log_messages.append(f"ğŸ“ ç¬¬ä¸€ä¸ªè¯: {first_word}")
                
                log_messages.append(f"âœ… WhisperXå¯¹é½å®Œæˆ: {len(segments)} å¥, {len(words)} è¯")
                
            except Exception as align_error:
                log_messages.append(f"âš ï¸ WhisperXå¯¹é½å¤±è´¥: {align_error}")
                log_messages.append("ğŸ”„ è‡ªåŠ¨å›é€€åˆ°ASRåŸå§‹ç»“æœ")
                segments = transcribe_result["segments"]
                words = []
                
                # ä»segmentsç”Ÿæˆword-levelæ•°æ®ä½œä¸ºå¤‡ç”¨
                for segment in segments:
                    if "words" in segment and segment["words"]:
                        words.extend(segment["words"])
                    else:
                        # å¦‚æœsegmentæ²¡æœ‰wordsï¼Œç”Ÿæˆç®€å•çš„wordåˆ†å‰²
                        segment_words = self._generate_words_from_segment(segment)
                        words.extend(segment_words)
                
                log_messages.append(f"ğŸ“ ä»segmentsç”Ÿæˆäº† {len(words)} ä¸ªè¯çº§æ•°æ®")
            
            # ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½æ–‡æœ¬æ˜ å°„ï¼ˆå¦‚æœæä¾›å‚è€ƒæ–‡æœ¬ï¼‰
            if reference_text.strip():
                log_messages.append("ğŸ”„ ç¬¬ä¸‰æ­¥ï¼šæ™ºèƒ½æ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬...")
                # è‡ªåŠ¨æ¸…æ´—å‚è€ƒæ–‡æœ¬
                cleaned_text = self._auto_clean_text(reference_text)
                if len(cleaned_text) != len(reference_text):
                    log_messages.append(f"ğŸ§¹ æ–‡æœ¬è‡ªåŠ¨æ¸…æ´—: {len(reference_text)} -> {len(cleaned_text)} å­—ç¬¦")
                
                segments, words = self._map_to_reference_text(segments, words, cleaned_text, log_messages)
            else:
                log_messages.append("ğŸ“ ç¬¬ä¸‰æ­¥ï¼šæ— å‚è€ƒæ–‡æœ¬ï¼Œä¿æŒASRåŸå§‹ç»“æœ")
            
            # ç¡®ä¿æ€»æ˜¯æœ‰wordsæ•°æ®ç”¨äºå­—å¹•æ¸²æŸ“
            if len(words) == 0 and len(segments) > 0:
                log_messages.append("ğŸ”§ ç”Ÿæˆè¯çº§å¯¹é½æ•°æ®ä»¥æ”¯æŒå­—å¹•æ¸²æŸ“...")
                for segment in segments:
                    segment_words = self._generate_words_from_segment(segment)
                    words.extend(segment_words)
                log_messages.append(f"ğŸ“ ç”Ÿæˆäº† {len(words)} ä¸ªè¯ç”¨äºå­—å¹•æ¸²æŸ“")
            
            log_messages.append(f"ğŸ‰ å¯¹é½å®Œæˆ! å¥å­: {len(segments)}, è¯è¯­: {len(words)}")
            
            # æ ¼å¼åŒ–è¾“å‡ºä¸ºwhisper_alignmentæ ¼å¼
            segments_alignment = []
            words_alignment = []
            aligned_text_parts = []
            
            for segment in segments:
                # å¥çº§åˆ«å¯¹é½
                segment_data = {
                    "start": segment.get("start", 0.0),
                    "end": segment.get("end", 0.0),
                    "value": segment.get("text", "").strip(),
                    "confidence": segment.get("confidence", 1.0)
                }
                segments_alignment.append(segment_data)
                aligned_text_parts.append(segment_data["value"])
            
            # ğŸš¨ ä¿®å¤ï¼šç›´æ¥å¤„ç†wordså˜é‡ï¼Œè€Œä¸æ˜¯ä»segmentsä¸­é‡æ–°æå–
            for word in words:
                word_data = {
                    "start": word.get("start", 0.0),
                    "end": word.get("end", 0.0),
                    "value": word.get("word", "").strip(),
                    "confidence": word.get("score", word.get("confidence", 1.0))
                }
                words_alignment.append(word_data)
            
            # ç”Ÿæˆå¯¹é½åçš„å®Œæ•´æ–‡æœ¬
            aligned_text = " ".join(aligned_text_parts)
            log_messages.append(f"ğŸ“„ ç”Ÿæˆæœ€ç»ˆæ–‡æœ¬: {len(aligned_text)} å­—ç¬¦")
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.remove(audio_save_path)
                log_messages.append("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
            except Exception as e:
                log_messages.append(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}")
            
            log_messages.append(f"ğŸ“Š å¤„ç†ç»Ÿè®¡:")
            log_messages.append(f"  - å¯¹é½å¥å­æ•°: {len(segments_alignment)}")
            log_messages.append(f"  - å¯¹é½è¯è¯­æ•°: {len(words_alignment)}")
            log_messages.append(f"  - æ£€æµ‹è¯­è¨€: {detected_language}")
            if reference_text.strip():
                log_messages.append(f"  - æ–‡æœ¬åŒ¹é…åº¦: {self._calculate_text_similarity(reference_text, aligned_text):.1%}")
            
            # è´¨é‡è¯„ä¼°
            low_confidence_count = len([s for s in segments if s.get("confidence", 1.0) < 0.8])
            if low_confidence_count > 0:
                log_messages.append(f"ğŸ’¡ è´¨é‡æç¤º: {low_confidence_count} ä¸ªç‰‡æ®µç½®ä¿¡åº¦è¾ƒä½")
                log_messages.append("   å»ºè®®æ£€æŸ¥éŸ³é¢‘è´¨é‡æˆ–å‚è€ƒæ–‡æœ¬åŒ¹é…åº¦")
            
            log_messages.append("ğŸ‰ å¤„ç†å®Œæˆï¼å‡†å¤‡è¿”å›ç»“æœ...")
            
            # æœ€ç»ˆéªŒè¯å’Œå¼ºåˆ¶æ—¥å¿—
            final_log = "\n".join(log_messages)
            result_summary = f"WhisperXå¤„ç†å®Œæˆ: {len(segments_alignment)} å¥, {len(words_alignment)} è¯, æœ€ç»ˆæ–‡æœ¬é•¿åº¦: {len(aligned_text)}"
            logger.info(result_summary)
            
            # å¼ºåˆ¶è¾“å‡ºå…³é”®è°ƒè¯•ä¿¡æ¯åˆ°console
            if len(words_alignment) == 0:
                logger.error("âŒ ä¸¥é‡é—®é¢˜ï¼šwords_alignmentä¸ºç©ºï¼")
                logger.error(f"åŸå§‹wordsæ•°æ®é•¿åº¦: {len(words)}")
                if words:
                    logger.error(f"ç¬¬ä¸€ä¸ªåŸå§‹word: {words[0]}")
            else:
                logger.info(f"âœ… æˆåŠŸç”Ÿæˆ {len(words_alignment)} ä¸ªè¯çº§å¯¹é½æ•°æ®")
            
            return aligned_text, segments_alignment, words_alignment, final_log
            
        except Exception as e:
            error_msg = f"WhisperXå¯¹é½è¿‡ç¨‹å‘ç”Ÿé”™è¯¯: {e}"
            logger.error(error_msg)
            import traceback
            logger.error(traceback.format_exc())
            
            # æä¾›å…·ä½“çš„é”™è¯¯åˆ†æå’Œè§£å†³å»ºè®®
            error_analysis = self._analyze_error(str(e))
            log_messages.append(f"âŒ {error_msg}")
            if error_analysis:
                log_messages.extend(error_analysis)
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if 'audio_save_path' in locals():
                    os.remove(audio_save_path)
            except:
                pass
            
            return "", [], [], "\n".join(log_messages)
    
    def _get_language_code(self, language: str) -> str:
        """å°†è¯­è¨€åç§°è½¬æ¢ä¸ºä»£ç """
        language_mapping = {
            "auto": None,
            "chinese": "zh",
            "english": "en", 
            "japanese": "ja",
            "korean": "ko",
            "french": "fr",
            "german": "de", 
            "spanish": "es",
            "italian": "it"
        }
        return language_mapping.get(language.lower(), None)
    
    def _calculate_text_similarity(self, text1: str, text2: str) -> float:
        """è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆç®€å•å®ç°ï¼‰"""
        if not text1 or not text2:
            return 0.0
        
        # ç®€å•çš„è¯è¯­é‡å ç‡è®¡ç®—
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _prepare_reference_text(self, reference_text: str, language: str) -> List[str]:
        """é¢„å¤„ç†å‚è€ƒæ–‡æœ¬ï¼Œåˆ†å‰²æˆé€‚åˆå¯¹é½çš„å¥å­ç‰‡æ®µï¼Œå¹¶è¿›è¡Œè‡ªåŠ¨æ•°æ®æ¸…æ´—"""
        import re
        
        # æ¸…ç†æ–‡æœ¬ï¼ˆç°åœ¨æ€»æ˜¯å¯ç”¨æ¸…æ´—ï¼‰
        text = self._auto_clean_text(reference_text.strip())
        if not text:
            return []
        
        # æ ¹æ®è¯­è¨€ä½¿ç”¨ä¸åŒçš„åˆ†å¥ç­–ç•¥
        if language in ['zh', 'ja', 'ko']:  # ä¸­æ—¥éŸ©è¯­è¨€
            # æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥
            sentences = re.split(r'[ã€‚ï¼ï¼Ÿï¼›\.\!\?;]', text)
        else:  # å…¶ä»–è¯­è¨€
            # æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å¥
            sentences = re.split(r'[\.!\?]+', text)
        
        # æ¸…ç†å¹¶è¿‡æ»¤ç©ºå¥å­
        processed_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence:
                # å¯¹äºè¿‡é•¿çš„å¥å­ï¼Œè¿›ä¸€æ­¥åˆ†å‰²
                if len(sentence) > 150:  # é™ä½é˜ˆå€¼ï¼Œæé«˜å¯¹é½æˆåŠŸç‡
                    # æŒ‰é€—å·æˆ–å…¶ä»–æ ‡ç‚¹è¿›ä¸€æ­¥åˆ†å‰²
                    sub_sentences = re.split(r'[,ï¼Œã€\(\)]', sentence)
                    for sub in sub_sentences:
                        sub = sub.strip()
                        if sub and len(sub) > 3:  # è¿‡æ»¤å¤ªçŸ­çš„ç‰‡æ®µ
                            processed_sentences.append(sub)
                else:
                    processed_sentences.append(sentence)
        
        return processed_sentences if processed_sentences else [text]
    
    def _auto_clean_text(self, text: str) -> str:
        """è‡ªåŠ¨æ¸…æ´—æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½å¯¼è‡´å¯¹é½å¤±è´¥çš„å…ƒç´ """
        import re
        
        # è®°å½•æ¸…æ´—æ“ä½œ
        original_length = len(text)
        
        # 1. ç§»é™¤ç‰¹æ®Šç¬¦å·å’Œæ ‡è®°
        # ç§»é™¤æ˜Ÿå·å¼ºè°ƒæ ‡è®° (å¦‚ *SOLVED*)
        text = re.sub(r'\*([^*]*)\*', r'\1', text)
        
        # ç§»é™¤äº•å·æ ‡ç­¾ (å¦‚ #hashtag)
        text = re.sub(r'#\w+', '', text)
        
        # ç§»é™¤å¤šä½™çš„æ ‡ç‚¹ç¬¦å·
        text = re.sub(r'[!]{2,}', '!', text)  # å¤šä¸ªæ„Ÿå¹å·
        text = re.sub(r'[?]{2,}', '?', text)  # å¤šä¸ªé—®å·
        text = re.sub(r'[.]{2,}', '...', text)  # å¤šä¸ªå¥å·è½¬çœç•¥å·
        
        # 2. å¤„ç†æ‹¬å·å†…å®¹
        # ç§»é™¤æ–¹æ‹¬å·åŠå…¶å†…å®¹ (å¦‚ [æ³¨é‡Š])
        text = re.sub(r'\[[^\]]*\]', '', text)
        
        # ç®€åŒ–é•¿çš„åœ†æ‹¬å·å†…å®¹
        def simplify_parentheses(match):
            content = match.group(1)
            if len(content) > 50:  # å¦‚æœæ‹¬å·å†…å®¹å¤ªé•¿ï¼Œç§»é™¤
                return ''
            return match.group(0)  # ä¿ç•™çŸ­çš„æ‹¬å·å†…å®¹
        
        text = re.sub(r'\(([^)]*)\)', simplify_parentheses, text)
        
        # 3. æ ‡å‡†åŒ–ç©ºç™½å­—ç¬¦
        text = re.sub(r'\s+', ' ', text)  # å¤šä¸ªç©ºç™½å­—ç¬¦åˆå¹¶ä¸ºå•ä¸ªç©ºæ ¼
        text = re.sub(r'\n+', ' ', text)  # æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
        
        # 4. ç§»é™¤é¦–å°¾å¤šä½™å­—ç¬¦
        text = text.strip(' .,;:')
        
        # 5. å¤„ç†æ•°å­—å’Œç‰¹æ®Šå­—ç¬¦ç»„åˆ
        # æ ‡å‡†åŒ–å¹´ä»½è¡¨ç¤º (å¦‚ 1978å¹´ -> 1978)
        text = re.sub(r'(\d{4})å¹´', r'\1', text)
        
        # æ ‡å‡†åŒ–ç™¾åˆ†æ¯” (å¦‚ 50% -> 50 percent)
        text = re.sub(r'(\d+)%', r'\1 percent', text)
        
        cleaned_length = len(text)
        if cleaned_length != original_length:
            logger.info(f"ğŸ§¹ æ–‡æœ¬æ¸…æ´—: {original_length} -> {cleaned_length} å­—ç¬¦")
        
        return text
    
    def _map_to_reference_text(self, segments: List[Dict], words: List[Dict], reference_text: str, log_messages: List[str]) -> Tuple[List[Dict], List[Dict]]:
        """å°†ASRè½¬å½•ç»“æœæ˜ å°„åˆ°å‚è€ƒæ–‡æœ¬ï¼ˆæ™ºèƒ½é™çº§æ–¹æ¡ˆï¼‰"""
        log_messages.append("ğŸ”„ æ‰§è¡ŒASR+æ™ºèƒ½æ–‡æœ¬æ˜ å°„...")
        
        # æå–ASRè½¬å½•çš„æ–‡æœ¬
        asr_text = " ".join([seg.get("text", "") for seg in segments])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarity = self._calculate_text_similarity(reference_text, asr_text)
        log_messages.append(f"ğŸ“Š ASRä¸å‚è€ƒæ–‡æœ¬ç›¸ä¼¼åº¦: {similarity:.1%}")
        
        if similarity > 0.3:  # é™ä½é˜ˆå€¼ï¼Œæ›´å®½æ¾çš„åŒ¹é…
            log_messages.append("âœ… ç›¸ä¼¼åº¦å¯æ¥å—ï¼Œä½¿ç”¨ASRå¯¹é½ç»“æœå¹¶è°ƒæ•´æ–‡æœ¬")
            
            # ä½¿ç”¨ASRçš„æ—¶é—´æˆ³ï¼Œä½†å°è¯•èåˆå‚è€ƒæ–‡æœ¬çš„å†…å®¹
            adjusted_segments = []
            reference_segments = self._prepare_reference_text(reference_text, "en")
            
            # æ™ºèƒ½èåˆï¼šæ—¶é—´æ¥è‡ªASRï¼Œå†…å®¹ä¼˜å…ˆä½¿ç”¨å‚è€ƒæ–‡æœ¬
            for i, asr_seg in enumerate(segments):
                if i < len(reference_segments):
                    # ä½¿ç”¨å‚è€ƒæ–‡æœ¬å†…å®¹ï¼Œä½†ä¿æŒASRçš„æ—¶é—´æˆ³
                    adjusted_segments.append({
                        "start": asr_seg.get("start", 0.0),
                        "end": asr_seg.get("end", 0.0),
                        "text": reference_segments[i],
                        "confidence": max(0.6, asr_seg.get("confidence", 0.8))  # ç¨å¾®æé«˜ç½®ä¿¡åº¦
                    })
                else:
                    # å¦‚æœå‚è€ƒæ–‡æœ¬ç‰‡æ®µä¸å¤Ÿï¼Œä¿æŒåŸASRç»“æœ
                    adjusted_segments.append(asr_seg)
            
            # å¦‚æœå‚è€ƒæ–‡æœ¬è¿˜æœ‰å‰©ä½™ï¼ŒæŒ‰æ¯”ä¾‹åˆ†é…åˆ°æœ«å°¾
            if len(reference_segments) > len(segments) and segments:
                last_end = segments[-1].get("end", 0.0)
                remaining_segments = reference_segments[len(segments):]
                
                # ä¸ºå‰©ä½™æ–‡æœ¬åˆ†é…æ—¶é—´ï¼ˆå‡è®¾æ¯æ®µ3ç§’ï¼‰
                for i, ref_text in enumerate(remaining_segments):
                    start_time = last_end + i * 3.0
                    end_time = start_time + 3.0
                    adjusted_segments.append({
                        "start": start_time,
                        "end": end_time,
                        "text": ref_text,
                        "confidence": 0.5  # è¾ƒä½ç½®ä¿¡åº¦ï¼Œå› ä¸ºæ˜¯ä¼°ç®—æ—¶é—´
                    })
            
            log_messages.append(f"ğŸ”— æ™ºèƒ½èåˆå®Œæˆ: {len(adjusted_segments)} å¥")
            return adjusted_segments, words  # ä¿æŒåŸæœ‰è¯çº§å¯¹é½
            
        else:
            log_messages.append("âš ï¸ ç›¸ä¼¼åº¦å¾ˆä½ï¼Œä½¿ç”¨çº¯æ—¶é—´åˆ†å‰²æ–¹æ¡ˆ...")
            
            # å®Œå…¨åŸºäºæ—¶é—´çš„å‡åŒ€åˆ†å‰²ï¼ˆæœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼‰
            reference_segments = self._prepare_reference_text(reference_text, "en")
            
            # è®¡ç®—æ€»æ—¶é•¿
            if segments:
                total_duration = max([seg.get("end", 0) for seg in segments])
            else:
                total_duration = 30.0  # é»˜è®¤30ç§’
            
            # å‡åŒ€åˆ†å‰²æ—¶é—´
            segment_duration = total_duration / len(reference_segments) if reference_segments else 3.0
            
            uniform_segments = []
            for i, ref_text in enumerate(reference_segments):
                start_time = i * segment_duration
                end_time = (i + 1) * segment_duration
                
                uniform_segments.append({
                    "start": start_time,
                    "end": min(end_time, total_duration),  # ç¡®ä¿ä¸è¶…è¿‡æ€»æ—¶é•¿
                    "text": ref_text,
                    "confidence": 0.4  # ä½ç½®ä¿¡åº¦ï¼Œå› ä¸ºæ˜¯å®Œå…¨ä¼°ç®—
                })
            
            # ç”Ÿæˆå¯¹åº”çš„è¯çº§å¯¹é½
            uniform_words = []
            for seg in uniform_segments:
                seg_duration = seg["end"] - seg["start"]
                seg_words = seg["text"].split()
                if seg_words and seg_duration > 0:
                    word_duration = seg_duration / len(seg_words)
                    for j, word in enumerate(seg_words):
                        word_start = seg["start"] + j * word_duration
                        word_end = min(word_start + word_duration, seg["end"])
                        uniform_words.append({
                            "start": word_start,
                            "end": word_end,
                            "word": word,
                            "confidence": 0.4
                        })
            
            log_messages.append(f"ğŸ“ å‡åŒ€åˆ†å‰²å®Œæˆ: {len(uniform_segments)} å¥, {len(uniform_words)} è¯")
            log_messages.append("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥å‚è€ƒæ–‡æœ¬æ˜¯å¦ä¸éŸ³é¢‘å†…å®¹åŒ¹é…")
            return uniform_segments, uniform_words
    
    def _analyze_error(self, error_str: str) -> List[str]:
        """åˆ†æé”™è¯¯å¹¶æä¾›è§£å†³å»ºè®®"""
        suggestions = []
        
        if "incompatible constructor arguments" in error_str and "ctranslate2" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°CTranslate2ç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ›´æ–°WhisperX: pip install --upgrade whisperx",
                "   2. æˆ–é™çº§CTranslate2: pip install ctranslate2==3.24.0", 
                "   3. æˆ–ä½¿ç”¨å…¼å®¹ç‰ˆæœ¬: pip install whisperx==3.1.1",
                "   4. æ£€æŸ¥CUDAç‰ˆæœ¬å…¼å®¹æ€§"
            ])
        
        elif "unsupported device" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡æ ¼å¼ä¸å…¼å®¹é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. å·²è‡ªåŠ¨ä¿®å¤è®¾å¤‡æ ¼å¼è½¬æ¢",
                "   2. å¦‚æœé—®é¢˜æŒç»­ï¼Œå°è¯•é‡å¯ComfyUI",
                "   3. æ£€æŸ¥CUDAé©±åŠ¨æ˜¯å¦æ­£å¸¸å·¥ä½œ",
                "   4. å°è¯•ä½¿ç”¨CPUæ¨¡å¼æµ‹è¯•"
            ])
        
        elif "has no attribute 'parameters'" in error_str or "has no attribute" in error_str:
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹ç»“æ„å…¼å®¹æ€§é—®é¢˜ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. âœ… å·²è‡ªåŠ¨ä¿®å¤æ¨¡å‹å¤§å°ä¼°ç®—æ–¹æ³•",
                "   2. å°è¯•é‡å¯ComfyUIé‡æ–°åŠ è½½ä¿®å¤åçš„ä»£ç ",
                "   3. å¦‚æœé—®é¢˜æŒç»­ï¼Œæ£€æŸ¥WhisperXç‰ˆæœ¬å…¼å®¹æ€§",
                "   4. è€ƒè™‘é™çº§åˆ°å…¼å®¹ç‰ˆæœ¬: pip install whisperx==3.1.1"
            ])
        
        elif "device" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°è®¾å¤‡ç›¸å…³é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥CUDAæ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. å°è¯•ä½¿ç”¨CPUæ¨¡å¼",
                "   3. é‡å¯ComfyUIé‡æ–°åˆå§‹åŒ–è®¾å¤‡"
            ])
        
        elif "memory" in error_str.lower() or "oom" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°å†…å­˜ä¸è¶³ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ (å¦‚ baseã€small)",
                "   2. é™ä½batch_size",
                "   3. å…³é—­å…¶ä»–å ç”¨GPUå†…å­˜çš„ç¨‹åº"
            ])
        
        elif "model" in error_str.lower() and "load" in error_str.lower():
            suggestions.extend([
                "ğŸ”§ æ£€æµ‹åˆ°æ¨¡å‹åŠ è½½é”™è¯¯ï¼Œå»ºè®®è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥ç½‘ç»œè¿æ¥",
                "   2. æ¸…ç†æ¨¡å‹ç¼“å­˜ç›®å½•",
                "   3. æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹æ–‡ä»¶"
            ])
        
        else:
            suggestions.extend([
                "ğŸ”§ é€šç”¨è§£å†³æ–¹æ¡ˆï¼š",
                "   1. æ£€æŸ¥æ‰€æœ‰ä¾èµ–æ˜¯å¦æ­£ç¡®å®‰è£…",
                "   2. é‡å¯ComfyUI",
                "   3. æŸ¥çœ‹å®Œæ•´é”™è¯¯æ—¥å¿—",
                "   4. å°è¯•ä½¿ç”¨è¾ƒå°çš„éŸ³é¢‘æ–‡ä»¶æµ‹è¯•"
            ])
        
        return suggestions
    
    def _generate_words_from_segment(self, segment: Dict) -> List[Dict]:
        """ä»segmentç”Ÿæˆç®€å•çš„è¯çº§å¯¹é½æ•°æ®"""
        words = []
        text = segment.get("text", "").strip()
        start_time = segment.get("start", 0.0)
        end_time = segment.get("end", 0.0)
        duration = end_time - start_time
        
        if not text or duration <= 0:
            return words
        
        # ç®€å•åœ°æŒ‰ç©ºæ ¼åˆ†è¯
        word_list = text.split()
        if not word_list:
            return words
        
        # å¹³å‡åˆ†é…æ—¶é—´
        word_duration = duration / len(word_list)
        
        for i, word in enumerate(word_list):
            word_start = start_time + i * word_duration
            word_end = word_start + word_duration
            
            words.append({
                "word": word,
                "start": word_start,
                "end": word_end,
                "confidence": segment.get("confidence", 0.8)
            })
        
        return words


# èŠ‚ç‚¹æ³¨å†Œ
NODE_CLASS_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": ApplyWhisperXAlignmentNode
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "ApplyWhisperXAlignmentNode": "ğŸ¯ WhisperX å¼ºåˆ¶å¯¹é½ (Forced Alignment)"
}


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    print("ğŸµ WhisperXå¼ºåˆ¶å¯¹é½èŠ‚ç‚¹æµ‹è¯•")
    node = ApplyWhisperXAlignmentNode()
    print("ğŸ“‹ è¾“å…¥ç±»å‹:", node.INPUT_TYPES())
    print("ğŸ¯ è¿”å›ç±»å‹:", node.RETURN_TYPES)
    print("ğŸ“ è¿”å›åç§°:", node.RETURN_NAMES)